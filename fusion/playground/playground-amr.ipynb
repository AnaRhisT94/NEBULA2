{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4422f0-1ada-4324-8173-2fb89a605b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import bisect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib\n",
    "import subprocess\n",
    "import re\n",
    "import tempfile\n",
    "import itertools\n",
    "import torch\n",
    "import spacy\n",
    "import amrlib\n",
    "import penman\n",
    "\n",
    "from typing import List, Tuple\n",
    "from operator import itemgetter \n",
    "# import qgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79742a6-1df7-40ae-aec8-c3a3960e81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath(os.getcwd()+'/../..')  # /home/gil/dev/NEBULA2/\n",
    "os.chdir(os.getcwd()+'/../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41181f5b-01c9-4ff4-82bf-8819720dc6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nebula_api.nebula_enrichment_api import *\n",
    "from experts.common.RemoteAPIUtility import RemoteAPIUtility\n",
    "from nebula_api.mdmmt_api import mdmmt_api\n",
    "from nebula_api.atomic2020.comet_enrichment_api import *\n",
    "from nebula_api.canonisation_api import CANON_API\n",
    "from nlp_tools.light_house_generator import LightHouseGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9fe9d6-598c-499a-b08f-b548dcc3fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nebula_api.playground_api as pg_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddd9364-8b09-4c79-9fdc-e9329d40e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nre = NRE_API()\n",
    "api = RemoteAPIUtility()\n",
    "mdmmt = mdmmt_api.MDMMT_API()\n",
    "comet = Comet(\"/app/NEBULA2/nebula_api/atomic2020/comet-atomic_2020_BART\")\n",
    "ascore = CANON_API()\n",
    "stog = amrlib.load_stog_model(model_dir=\"/app/NEBULA2/models/model_stog\")\n",
    "gtos = amrlib.load_gtos_model(model_dir=\"/app/NEBULA2/models/model_gtos\")\n",
    "# lh_gen = LightHouseGenerator(comet,stog,gtos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dcd694-7362-4aa8-89e8-a6107f71ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = ['Movies/114206952',\n",
    "'Movies/114207205',\n",
    "'Movies/114207398',\n",
    "'Movies/114207499',\n",
    "'Movies/114207361',\n",
    "'Movies/114207740',\n",
    "'Movies/114207908',\n",
    "'Movies/114208744',\n",
    "'Movies/114206724',\n",
    "'Movies/114206548',\n",
    "'Movies/114206264']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e631f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript\n",
    "from IPython.display import HTML, display\n",
    "import base64\n",
    "\n",
    "\n",
    "def download_video_file(movie, fname='/tmp/video_file.mp4'):    \n",
    "    if os.path.exists(fname):\n",
    "        os.remove(fname)\n",
    "    query = 'FOR doc IN Movies FILTER doc._id == \"{}\" RETURN doc'.format(movie)\n",
    "    cursor = api.db.aql.execute(query)\n",
    "    url_prefix = \"http://ec2-18-159-140-240.eu-central-1.compute.amazonaws.com:7000/\"\n",
    "    url_link = ''\n",
    "    for doc in cursor:\n",
    "        url_link = url_prefix+doc['url_path']\n",
    "        url_link = url_link.replace(\".avi\", \".mp4\")   \n",
    "        print(url_link)\n",
    "        urllib.request.urlretrieve(url_link, fname) \n",
    "    return fname\n",
    "    # video = cv2.VideoCapture(self.temp_file)\n",
    "    # fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    # return(fps, url_link)\n",
    "\n",
    "\n",
    "\n",
    "def read_video_segm(abspath, t_beg, t_end):\n",
    "    cmd = f'ffmpeg -y -ss {t_beg} -i {abspath} -max_muxing_queue_size 9999  -loglevel error -f mp4 -vf scale=\"(floor(112/ih * iw/2))*2:112\"  -c:a copy  -movflags frag_keyframe+empty_moov -t {t_end - t_beg} pipe:1 -nostats -hide_banner -nostdin'\n",
    "    p = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE)\n",
    "    assert p.returncode == 0, cmd\n",
    "    buf = p.stdout\n",
    "    return buf\n",
    "\n",
    "video_id_cnt = 0    \n",
    "class VideoElem:\n",
    "    def __init__(self, fname, t_start=0, t_end=999):\n",
    "        with open(fname, 'rb') as f:\n",
    "            #data = base64.standard_b64encode(f.read())\n",
    "            buf = read_video_segm(fname, t_start, t_end)\n",
    "            data = base64.standard_b64encode(buf)\n",
    "        global video_id_cnt\n",
    "        video_id_cnt += 1\n",
    "        self.video_id_cnt = video_id_cnt\n",
    "        elem = HTML(f\"\"\"\n",
    "            <video id=\"video_{self.video_id_cnt}\" autoplay loop muted>\n",
    "                <source src=\"data:video/mp4;base64,{data.decode('ascii')}\" type=\"video/mp4\">\n",
    "            </video>        \n",
    "        \"\"\")\n",
    "        display(elem)\n",
    "    \n",
    "    def hide(self):\n",
    "        js = f'$(\"#video_{self.video_id_cnt}\").hide()'\n",
    "        display(Javascript(js))\n",
    "        \n",
    "    def show(self):\n",
    "        js = f'$(\"#video_{self.video_id_cnt}\").show()'\n",
    "        display(Javascript(js))\n",
    "\n",
    "    def remove(self):\n",
    "        js = f'$(\"#video_{self.video_id_cnt}\").remove()'\n",
    "        display(Javascript(js))\n",
    "        \n",
    "def mdmmt_video_encode(start_f, stop_f, path='/tmp/video_file.mp4', freq=24):\n",
    "        t_start = start_f//freq\n",
    "        t_end = stop_f//freq\n",
    "        if t_start == t_end:\n",
    "            t_start = t_start - 1\n",
    "        print(\"Start/stop\", t_start, \" \", t_end)\n",
    "        if (t_end - t_start) >= 1:\n",
    "            vemb = mdmmt.encode_video(\n",
    "                mdmmt.vggish_model,  # adio modality\n",
    "                mdmmt.vmz_model,  # video modality\n",
    "                mdmmt.clip_model,  # image modality\n",
    "                mdmmt.model_vid,  # aggregator\n",
    "                path, t_start, t_end)\n",
    "            return(vemb)\n",
    "        else:\n",
    "            print(\"Stage too short\")\n",
    "            return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78a56f-a2e5-40f5-8e85-2d94d3f357a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_concepts(frame)-> List:\n",
    "    def transform_concept(c):\n",
    "        exp = re.compile(r\"^([a-zA-z]+)(\\d*)$\")\n",
    "        r = exp.match(c)\n",
    "        return r.group(1) if r else c\n",
    "        \n",
    "    pre_concepts = set(frame['tracker_description']).union(set(frame['step_description'])).union(set(frame['simulated_expert']))\n",
    "    concepts = list(set(map(transform_concept,pre_concepts)))\n",
    "    return concepts\n",
    "\n",
    "def kgbart_fusion(frames) -> (List[str], List[str]):\n",
    "    h, outname = tempfile.mkstemp(text=True)\n",
    "    os.close(h)\n",
    "    h, fname = tempfile.mkstemp(text=True)\n",
    "    os.close(h)\n",
    "    KGBART_MAIN = BASE_DIR+'/kgbart/KGBART/KGBART_training/decode_seq2seq.py'\n",
    "    KGBART_CC_DIR = BASE_DIR+'/kgbart/downloaded/commongen_dataset'\n",
    "    KGBART_MODEL_DIR = BASE_DIR+'/kgbart/output/best_model/model.best.bin'\n",
    "    options = {\n",
    "        'data_dir': KGBART_CC_DIR,\n",
    "        'output_dir': os.path.dirname(outname),\n",
    "        'input_file': fname,\n",
    "        'model_recover_path': KGBART_MODEL_DIR,\n",
    "        'output_file': os.path.basename(outname),\n",
    "        'split': 'dev',\n",
    "        'beam_size': 5,\n",
    "        'forbid_duplicate_ngrams': True\n",
    "    }\n",
    "    all_concepts = []\n",
    "    with open(fname, 'w') as f:\n",
    "        for frame in frames:\n",
    "            concepts = frame_to_concepts(frame)\n",
    "            all_concepts.append(', '.join(concepts))\n",
    "            f.write(' '.join(concepts)+'\\n')\n",
    "        \n",
    "    # write expert tokens to input file\n",
    "    \n",
    "    cmdline = 'python '+KGBART_MAIN+' '+ ' '.join(['--{} {}'.format(k,v) for (k,v) in options.items()]) + '>/dev/null 2>&1'\n",
    "    os.system(cmdline)\n",
    "    with open(outname,'r') as f:\n",
    "        rc = f.readlines()\n",
    "    os.unlink(outname)\n",
    "    os.unlink(fname)\n",
    "    return all_concepts, rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243e402-1e54-466f-bf5a-e930ccc6d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst): return [x for l in lst for x in l]\n",
    "\n",
    "def compute_batch_scores(image_emb: torch.Tensor, texts: List[str]) -> List[float]:\n",
    "    emb_batch = mdmmt.batch_encode_text(texts)\n",
    "    return (emb_image.expand_as(emb_batch)*emb_batch).sum(dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "def compute_concat_score(image_emb: torch.Tensor, texts: List[str], join_on=',') -> float:\n",
    "    combined_text = \"\"\n",
    "    for t in [x.strip() for x in texts]:\n",
    "        if t[-1]=='.':\n",
    "            t = t[:-1]       \n",
    "        t+=join_on\n",
    "        t+=' '\n",
    "        combined_text+=t\n",
    "    print(\"Combined: \"+combined_text)\n",
    "    return torch.matmul(image_emb,mdmmt.encode_text(combined_text.strip()) )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bc58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_concept(c):\n",
    "    exp = re.compile(r\"^([a-zA-z]+)-?(\\d*)$\")\n",
    "    r = exp.match(c)\n",
    "    return r.group(1) if r else c\n",
    "\n",
    "class ConceptManager:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def ground_concept(concept):\n",
    "        return transform_concept(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5004e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityManager:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "    def similarity(self, c1, c2):\n",
    "        if type(c2) is not list:\n",
    "            c2 = [c2]   \n",
    "        a = self.nlp(c1)\n",
    "        targets = self.nlp(' '.join(c2))\n",
    "        return [a.similarity(x) for x in targets]\n",
    "\n",
    "\n",
    "smanager = SimilarityManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = lambda x: np.exp(x)/sum(np.exp(x))\n",
    "\n",
    "class SubsetOptimization:\n",
    "    def __init__(self, video_emb, experts: List, candidates_strings: List[str]):\n",
    "        self.stog = amrlib.load_stog_model(model_dir=\"/app/NEBULA2/models/model_stog\")\n",
    "        self.video_emb = video_emb\n",
    "        self.initial_temp = 10\n",
    "        self.final_temp = .05\n",
    "        self.alpha = 0.01\n",
    "        self.theta = 0.5\n",
    "        self.experts = experts\n",
    "        self.candidates_strings = candidates_strings\n",
    "        self.candidates_amr_strings = self.stog.parse_sents(self.candidates_strings) \n",
    "        self.candidates = self.candidates_amr_strings\n",
    "        self.candidates_amrs = [penman.decode(x) for x in self.candidates_amr_strings]\n",
    "        self.candidates_similarity = compute_batch_scores(self.video_emb, self.candidates_strings)             \n",
    "        self.opt_results = []\n",
    "        self.smanager = SimilarityManager()\n",
    "\n",
    "        self.coverage_matrix = np.zeros([len(self.experts),len(self.candidates)])\n",
    "        self.coverage_matrix[:] = np.nan\n",
    "        for i in range(len(experts)):\n",
    "            for j in range(len(candidates_strings)):\n",
    "                self.coverage_matrix[i][j]=self.concept_amr_similarity(self.experts[i],self.candidates_amrs[j])\n",
    "        self.max_size = int(len(self.experts)*1.5)\n",
    "\n",
    "    def concept_amr_similarity(self, concept, amr):\n",
    "        insts = [ConceptManager.ground_concept(x.target) for x in amr.instances()]\n",
    "        sims = self.smanager.similarity(concept, insts)\n",
    "        return max(sims)\n",
    "\n",
    "    def get_coverage(self,i,j):        \n",
    "        if np.isnan(self.coverage_matrix[i][j]):\n",
    "            self.coverage_matrix[i][j] = self.concept_amr_similarity(self.experts[i],self.candidates_amrs[j])\n",
    "        return self.coverage_matrix[i][j]\n",
    "\n",
    "    def get_expert_coverage(self,state):\n",
    "        return self.coverage_matrix[:,state].max(axis=1)\n",
    "\n",
    "    def get_state_coverage(self,state) -> float:\n",
    "        print(\"State coverage for {}:\".format(state))\n",
    "        print(self.get_expert_coverage(state))\n",
    "        return np.mean(self.get_expert_coverage(state))\n",
    "\n",
    "    # def get_state_coverage(self, state: List[int]) -> float:\n",
    "    #     experts_coverage = [max([self.get_coverage(i,j) for j in state]) for i in range(len(self.experts))]    # A list of partial coverege        \n",
    "    #     return sum(experts_coverage) / len(self.experts)\n",
    "\n",
    "    def get_cost(self, state: List[int]) -> float:\n",
    "        if not state:\n",
    "            return 0\n",
    "        coverage_score = self.get_state_coverage(state)           \n",
    "        similarity_score = self.candidates_similarity[state].mean().item()\n",
    "        return -(coverage_score + self.theta*similarity_score)\n",
    "\n",
    "    # state here is assumed (and guaranteed on return) to be -sorted-\n",
    "    def get_candidate(self, state: List[int]) -> List[int]:\n",
    "        def compute_state_arrays(s):\n",
    "            print(\"Computing arrays for state: \")\n",
    "            print(s)\n",
    "            s_score = self.candidates_similarity[s]\n",
    "            s_coverage = self.coverage_matrix.mean(axis=0)[s]\n",
    "            s_max_coverage = self.coverage_matrix.max(axis=0)[s]\n",
    "            s_fitscore = s_coverage+self.theta*s_score\n",
    "\n",
    "            return (s_score,s_coverage,s_max_coverage,s_fitscore)\n",
    "\n",
    "        if not state:\n",
    "            print(\"Empty state\")\n",
    "            return [random.randint(0,len(self.candidates_strings)-1)]\n",
    "            \n",
    "        rc = state.copy()\n",
    "        s = np.array(state)\n",
    "        s_score, s_coverage, s_max_coverage, s_fitscore = compute_state_arrays(s)\n",
    "               \n",
    "        if len(state) == self.max_size:\n",
    "            print(\"Maximum state size, removing\")\n",
    "            idx = np.argmin(s_fitscore)\n",
    "            del rc[idx]\n",
    "            return rc\n",
    "            \n",
    "        remove_sentence = random.random()<self.get_state_coverage(state)        \n",
    "        print(\"coverage of {} is {}, remove?{}\".format(state,self.get_state_coverage(state),remove_sentence))\n",
    "        if remove_sentence:             # We decide to remove a sentence from the set\n",
    "            print(\"Removing\")\n",
    "            probs = softmax(-s_fitscore)\n",
    "            idx = np.random.multinomial(1,probs).argmax()\n",
    "            del rc[idx]                   \n",
    "        else:                           # Add a sentence from the outside\n",
    "            print(\"Adding\")\n",
    "            anti_state = []\n",
    "            for i in range(len(self.candidates_strings)):\n",
    "                if not i in state:\n",
    "                    anti_state.append(i)\n",
    "            s1 = np.array(anti_state)\n",
    "            s1_score, s1_coverage, s1_max_coverage, s1_fitscore = compute_state_arrays(s1)\n",
    "            # Pick an expert to try and cover\n",
    "            probs = softmax(self.get_expert_coverage(s)*10)         # Coverage is in (0,1), so we use low temprature\n",
    "            expert_to_cover = np.random.multinomial(1,probs).argmax()\n",
    "            probs = softmax(self.coverage_matrix[expert_to_cover][s1]*10)\n",
    "            idx_to_add = np.random.multinomial(1,probs).argmax()\n",
    "            bisect.insort(rc,anti_state[idx_to_add])\n",
    "            \n",
    "        return rc\n",
    "\n",
    "\n",
    "\n",
    "    def get_scored_permutations(self, k):\n",
    "        n = len(self.candidates)\n",
    "        return [(x,self.get_cost(list(x))) for x in itertools.permutations(range(n),k)]\n",
    "        \n",
    "    def simulated_annealing(self, initial_state):\n",
    "        self.opt_results = []\n",
    "        current_temp = self.initial_temp\n",
    "\n",
    "       # Start by initializing the current state with the initial state\n",
    "        current_state = initial_state\n",
    "\n",
    "        while current_temp > self.final_temp:\n",
    "            next_cand = self.get_candidate(current_state)\n",
    "\n",
    "            print(\"current cost: {} ({}). Candidate cost: {} ({})\".format(self.get_cost(current_state),current_state,self.get_cost(next_cand),next_cand))\n",
    "\n",
    "            # Check if next_cand is best so far\n",
    "            cost_diff = self.get_cost(current_state) - self.get_cost(next_cand)\n",
    "\n",
    "            # if the new solution is better, accept it\n",
    "            if cost_diff > 0:\n",
    "                current_state = next_cand\n",
    "            # if the new solution is not better, accept it with a probability of e^(-cost/temp)\n",
    "            else:\n",
    "                print(\"chance to move: {}\".format(math.exp(cost_diff / current_temp)))\n",
    "                if random.uniform(0, 1) < math.exp(cost_diff / current_temp):\n",
    "                    current_state = next_cand\n",
    "            # decrement the temperature\n",
    "            current_temp -= self.alpha\n",
    "            self.opt_results.append(-self.get_cost(current_state))\n",
    "\n",
    "        return current_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb8a2c1-993e-479d-ab98-47572ac0452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_concepts(mid, scene_elem, use_db=False):\n",
    "    if use_db:\n",
    "        return nre.get_groundings_from_db(mid, scene_elem)\n",
    "    \n",
    "    concepts, attributes, persons, triplets, verbs = lh_gen.decompose_lighthouse(events=events, actions=[],\n",
    "                                                                             places=places)\n",
    "    concepts = flatten(concepts.values())\n",
    "    attributes = flatten(attributes.values())\n",
    "    triplets = flatten(triplets.values())\n",
    "    persons = flatten(persons.values())\n",
    "    \n",
    "    return concepts, attributes, persons, triplets, verbs['verbs']\n",
    "\n",
    "# get sets of concepts and triplets and return set of amrs/sentences\n",
    "\n",
    "def generate_candidates(concepts, attributes, persons, triplets, verbs):\n",
    "    return lh_gen.generate_from_concepts(concepts, attributes, persons, triplets, verbs,\n",
    "                                                    places, None)\n",
    "    \n",
    "# def fusion_pipeline(mid: str, scene_elem: int, **kwargs):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7bd7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get a list of 1-item dictionaries, return a list of the values\n",
    "'''\n",
    "\n",
    "def rearrange_concepts(concepts):\n",
    "    return [list(x.values())[0] for x in concepts]\n",
    "\n",
    "def permute_sentence(sentence, concepts):    \n",
    "    def replace_instance(g: penman.Graph, changes: List[tuple[int,str]]) -> penman.Graph :\n",
    "        amr_copy = penman.Graph(triples=g.triples, epidata=g.epidata)\n",
    "        for (i,val) in changes:\n",
    "            b = list(amr_copy.triples[i])\n",
    "            b[2] = val\n",
    "            amr_copy.triples[i] = tuple(b)\n",
    "        return amr_copy\n",
    "\n",
    "    concepts = {k: rearrange_concepts(v) for (k,v) in concepts.items()}\n",
    "    s = re.sub('[0-9]+', 'man', sentence.strip())\n",
    "    # s = re.sub('___', 'man', x.strip())\n",
    "    print(\"Original Sentence: {}\".format(s))\n",
    "    [amr] = stog.parse_sents([s])\n",
    "    pen = penman.decode(amr)\n",
    "    insts_list = []\n",
    "    rc = []\n",
    "    dims = []\n",
    "    for i,triplet in enumerate(pen.triples):\n",
    "        if triplet[1] == ':instance':\n",
    "            entity_class = ascore.get_class_of_entity(transform_concept(triplet[2]))\n",
    "            if entity_class == 'none':                          # This instance has no class, so we create its own special class to take care of the edge case\n",
    "                entity_class = 'none{}'.format(i)\n",
    "                concepts[entity_class] = []\n",
    "            if triplet[2] not in concepts[entity_class]:\n",
    "                concepts[entity_class].append(triplet[2])\n",
    "            insts_list.append((i,triplet, entity_class))\n",
    "            dims.append(range(len(concepts[entity_class])))\n",
    "    prods = itertools.product(*dims)\n",
    "    for cand in prods:        \n",
    "        changes = [(insts_list[i][0],concepts[insts_list[i][2]][d]) for (i,d) in enumerate(cand)]\n",
    "        rc.append(replace_instance(pen,changes))\n",
    "    \n",
    "    return pen, rc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6337b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = movies[1]\n",
    "events, places = comet.get_playground_data(mid, 0)\n",
    "video = VideoElem(download_video_file(mid))\n",
    "movie_info = api.get_movie_info(mid)\n",
    "emb_image = mdmmt_video_encode(*movie_info['scene_elements'][0])\n",
    "movie_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a89052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences = [x[0] for x in z4[-10:]]\n",
    "sentences = ['woman in the alleyway',\n",
    "             'woman alley outside apartments',\n",
    "             'woman enters the narrow street',\n",
    "             'woman need find a dark street corner',\n",
    "             'woman the dark street corner',\n",
    "             'woman need to find the alley way',\n",
    "             'woman sees the friend across the street',\n",
    "             'woman need to find a narrow street',\n",
    "             'woman narrow street',\n",
    "             'woman  the alleyway']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c5ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nre.get_groundings_from_db(\"Movies/114206816\",0)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe78ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '1 seem like she cannot believe what she is seeing'\n",
    "pen, rc = permute_sentence(s,data['concepts'][s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = gtos.generate([penman.encode(x) for x in rc[:10000]])\n",
    "# penman.encode(pen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e433a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = compute_batch_scores(emb_image, bla[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b36b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = list(rc['triplets'].keys())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a245485",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub('[0-9]+','___',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a36ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = [(x,ascore.get_class_of_entity(x)) for x in [\"stand\", \"sit\", \"take\", \"give\", \"look\", \"see\", \"smile\", \"eat\", \"hold\", \"drink\", \"put\", \"think\", \"comprehend\", \"speak\", \"talk\", \"raise\", \"pick\", \"announce\", \"laugh\", \"run\", \"walk\"]]\n",
    "print('-------------------------------------------------------')\n",
    "print(rc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SubsetOptimization(emb_image, [\"woman\", \"friend\", \"dark\", \"hurry\"], sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rc = opt.get_scored_permutations(3)\n",
    "rc = opt.simulated_annealing([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aae0918",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "sns.lineplot(x=(range(len(opt.opt_results))),y=opt.opt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70d6efa-38a3-4034-b57d-5b659abe14a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = nre.get_groundings_from_db(mid, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd4bc9-610f-4104-984e-803f35c5636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc['verbs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c78a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts, attributes, persons, triplets, verbs = lh_gen.decompose_lighthouse(events=events, actions=[],\n",
    "                                                                             places=places)\n",
    "\n",
    "concepts = flatten(concepts.values())\n",
    "attributes = flatten(attributes.values())\n",
    "triplets = flatten(triplets.values())\n",
    "persons = flatten(persons.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5e983-da6c-463a-bd7c-9449a9de54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = [x.strip() for x in [' suitcase', ' car', ' car seat']]\n",
    "attributes = [x.strip() for x in [' hurriedly', ' rushed', ' hurried']]\n",
    "persons = [x.strip() for x in [' gets hit by a car', ' to get in the car', ' to get to the car']]\n",
    "triplets = [x.strip() for x in [' PersonX gets hit by a car',\n",
    " ' PersonX steps off of the curb',\n",
    " ' PersonX is running late for work']]\n",
    "verbs = {}\n",
    "verbs['verbs'] = [x.strip() for x in ['get', 'accept', 'acquire']]\n",
    "places = [x.strip() for x in ['on a narrow street or alley',\n",
    " 'on a narrow street',\n",
    " 'outside in a large alley']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f6dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sent = lh_gen.generate_from_concepts(concepts[:3], attributes[:3], persons[:3], triplets[:3], verbs['verbs'][:3],\n",
    "                                                    places[:3], None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cands = comet.get_groundings(events,places,type=\"triplet\")\n",
    "for c in cands.keys():\n",
    "    texts = cands[c]\n",
    "    cands[c] = [x for x in texts if x.strip()]\n",
    "# compute_batch_scores(embamrs = stog.parse_sents(sentences)_image,[\"woman hurriedly steps off of the curb into the street carrying her luggage to the car\", \"hurriedly steps out of the street\", \"hurriedly steps out of the street carrying her luggage to the car\"])\n",
    "# compute_batch_scores(emb_image,[\"man is wearing a wide-brimmed hat\", \"man is wearing a wide - brimmed floral hat\", \"man wants to take off their hat\", \"man with a hat\"])\n",
    "# compute_batch_scores(emb_image,[\"woman hurriedly steps off of the curb into the street carrying her luggage to the car\", \"woman hurriedly steps out of the street\", \"woman hurriedly steps out of the street carrying her luggage to the car\"])\n",
    "diffs = []\n",
    "orig_c = []\n",
    "best_c = []\n",
    "all_output = []\n",
    "all_scores = []\n",
    "inp_scores = []\n",
    "for c in cands.keys():\n",
    "    # print('working on: {}'.format(c))\n",
    "    final_cands = [re.sub('PersonX', 'woman', x.strip()) for x in cands[c]]\n",
    "    final_c = re.sub('PersonX', 'woman', c.strip())\n",
    "    orig_score = compute_batch_scores(emb_image, [final_c])\n",
    "    rc = compute_batch_scores(emb_image, final_cands)\n",
    "    best_score = rc.max()\n",
    "    ind = rc.cpu().numpy().argmax()\n",
    "    all_output.append(final_cands)\n",
    "    all_scores.append(rc)\n",
    "    orig_c.append(final_c)\n",
    "    inp_scores.append(orig_score)\n",
    "    best_c.append(final_cands[ind])\n",
    "    diffs.append(rc.max()-orig_score[0])\n",
    "    # print(\"orig score for {}: {}. Max score after: {}. Diff: {}\".format(final_c,orig_score,rc.max(), rc.max()-orig_score[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3eefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "['{} -> {} : {}'.format(x,y,z.item()) for (x,y,z) in zip(orig_c,best_c,diffs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = [x for l in all_output for x in l]\n",
    "z2 = torch.concat(all_scores)\n",
    "z3 = list(zip(z1,[round(x,4) for x in z2.cpu().tolist()]))\n",
    "z3 = list(set(z3))\n",
    "z4 = sorted(z3,key=lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.candidates_similarity.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f901a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemgetter(*list(reversed(sorted(rc,key = lambda x: x[1])))[0][0])(opt.candidates_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8223be31-5f6b-40e1-8340-ab99a19d6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "[b, c, d] = stog.parse_sents(['He comes from New York', 'man sits in a chair waiting for someone', \"he drives carefully\"])\n",
    "a = penman.decode(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dbda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(a.triples[-3])\n",
    "b[2] = \"love\"\n",
    "a.triples[-3] = tuple(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83177554",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = penman.Graph(triples=a.triples,\n",
    "      epidata=a.epidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca896b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1.triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05841e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.triples.index(a._filter_triples('c', ':instance', None)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f81a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6635ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "penman.encode(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ec550",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtos.generate([penman.encode(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555690bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_amr_similarity(\"male\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "z = nlp('dog cat milk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9bc53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtos = amrlib.load_gtos_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = stog.parse_sents(['The woman looks at a rabid dog as it bites an old, well-dressed man',\n",
    "                     'I was late to the airport and almost missed my flight'])\n",
    "gtos.generate(z)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e59dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ascore.get_concept_from_entity('friendship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d65537",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConceptManager.ground_concept('bite-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9705fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639c55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_giltest('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0dd894",
   "metadata": {},
   "outputs": [],
   "source": [
    "WordNetLemmatizer().lemmatize('chairs', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies = comet.get_playground_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f87127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in all_movies:\n",
    "    df = pg_api.get_or_create_normalized_video(m)\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c2ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "BASE_DIR = os.path.abspath(os.getcwd()+'/../..')  # /home/gil/dev/NEBULA2/\n",
    "os.chdir(os.getcwd()+'/../..')\n",
    "from nebula_api.mdmmt_api import mdmmt_api\n",
    "mdmmt = mdmmt_api.MDMMT_API()\n",
    "def mdmmt_video_encode(start_f, stop_f, path='/tmp/video_file.mp4', freq=24):\n",
    "    t_start = start_f//freq\n",
    "    t_end = stop_f//freq\n",
    "    if t_start == t_end:\n",
    "        t_start = t_start - 1\n",
    "    print(\"Start/stop\", t_start, \" \", t_end)\n",
    "    if (t_end - t_start) >= 1:\n",
    "        vemb = mdmmt.encode_video(\n",
    "            mdmmt.vggish_model,  # adio modality\n",
    "            mdmmt.vmz_model,  # video modality\n",
    "            mdmmt.clip_model,  # image modality\n",
    "            mdmmt.model_vid,  # aggregator\n",
    "            path, t_start, t_end)\n",
    "        return(vemb)\n",
    "    else:\n",
    "        print(\"Stage too short\")\n",
    "        return(None)\n",
    "emb_image = mdmmt_video_encode(0,48)        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dfe4d185a1b3661f8d189d2dcb52f070789ba26e5d1ea6f8391b638319fa460"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
