{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3fa80b06",
      "metadata": {
        "id": "3fa80b06"
      },
      "source": [
        "# Best Implementation on Subtask A: Validation\n",
        "Last updated on 21/02/2022\n",
        "\n",
        "#### Project Information:\n",
        "* Objective Task: SemEval 2020 Task 4 - Commonsense Validation and Explanation (ComVE)<br>\n",
        "* By: Ilan\n",
        " \n",
        "#### Task Description:\n",
        "The subtask A is a validation task. The purpose is to determine which of two similar natural language statements is against common sense.\n",
        "\n",
        "*Example:*  \n",
        "> Task: Which of the two statements is against common sense?  \n",
        "> Statement1: He put a turkey into the fridge.  \n",
        "> Statement2: He put an elephant into the fridge. \n",
        "\n",
        "#### Solution:\n",
        "This program will follow the steps:\n",
        "1. General Preparation  \n",
        "2. Data Processing \n",
        "3. Loading the Model and Optimizer  \n",
        "4. Training \n",
        "5. Testing \n",
        "\n",
        "\n",
        "Please Note:  \n",
        "1. In this implementation work, there is no validation process. Here, the validation dataset will be used as the training dataset to improve the performance of the best implementation.  \n",
        "2. The optimal model and hyperparameters selected by the experiment require large storage (about 19G) on the GPU. If you just want to see how this implementation works, you can use a smaller model and batch size."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d22dc05",
      "metadata": {
        "id": "7d22dc05"
      },
      "source": [
        "<!-- #### Task Description:\n",
        "The subtask A is a validation task. The purpose is going to tell which of two similar natural language statements is against common sense.\n",
        "\n",
        "*Example:* \n",
        "        \n",
        "    Task: Which statement of the two is against common sense?\n",
        "    Statement1: He put a turkey into the fridge.  \n",
        "    Statement2: He put an elephant into the fridge.    -->"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "my_file = \"./DataSet\"\n",
        "if not os.path.exists(my_file):\n",
        "  !unzip DataSet.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB3AiO6D3KDf",
        "outputId": "638f1d75-ca1d-4179-8756-5833205a538e"
      },
      "id": "fB3AiO6D3KDf",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  DataSet.zip\n",
            "   creating: DataSet/\n",
            "   creating: DataSet/Dev Data/\n",
            "  inflating: DataSet/Dev Data/subtaskA_dev_data.csv  \n",
            "  inflating: DataSet/Dev Data/subtaskA_gold_answers.csv  \n",
            "  inflating: DataSet/Dev Data/subtaskB_dev_data.csv  \n",
            "  inflating: DataSet/Dev Data/subtaskB_gold_answers.csv  \n",
            "  inflating: DataSet/Dev Data/subtaskC_dev_data.csv  \n",
            "  inflating: DataSet/Dev Data/subtaskC_gold_answers.csv  \n",
            "  inflating: DataSet/dev.csv         \n",
            "   creating: DataSet/Test Data/\n",
            "   creating: DataSet/Test Data/ExampleSubmission/\n",
            "  inflating: DataSet/Test Data/ExampleSubmission/submission.zip  \n",
            "  inflating: DataSet/Test Data/ExampleSubmission/subtaskA_answers.csv  \n",
            "  inflating: DataSet/Test Data/ExampleSubmission/subtaskB_answers.csv  \n",
            "  inflating: DataSet/Test Data/ExampleSubmission/subtaskC_answers.csv  \n",
            "  inflating: DataSet/Test Data/subtaskA_gold_answers.csv  \n",
            "  inflating: DataSet/Test Data/subtaskA_test_data.csv  \n",
            "  inflating: DataSet/Test Data/subtaskB_gold_answers.csv  \n",
            "  inflating: DataSet/Test Data/subtaskB_test_data.csv  \n",
            "  inflating: DataSet/Test Data/subtaskC_gold_answers.csv  \n",
            "  inflating: DataSet/Test Data/subtaskC_test_data.csv  \n",
            "  inflating: DataSet/test.csv        \n",
            "  inflating: DataSet/train.csv       \n",
            "   creating: DataSet/Training Data/\n",
            "  inflating: DataSet/Training Data/subtaskA_answers_all.csv  \n",
            "  inflating: DataSet/Training Data/subtaskA_data_all.csv  \n",
            "  inflating: DataSet/Training Data/subtaskB_answers_all.csv  \n",
            "  inflating: DataSet/Training Data/subtaskB_data_all.csv  \n",
            "  inflating: DataSet/Training Data/subtaskC_answers_all.csv  \n",
            "  inflating: DataSet/Training Data/subtaskC_data_all.csv  \n",
            "   creating: DataSet/Trial Data/\n",
            "  inflating: DataSet/Trial Data/taskA_trial_answer.csv  \n",
            "  inflating: DataSet/Trial Data/taskA_trial_data.csv  \n",
            "  inflating: DataSet/Trial Data/taskB_trial_answer.csv  \n",
            "  inflating: DataSet/Trial Data/taskB_trial_data.csv  \n",
            "  inflating: DataSet/Trial Data/taskC_trial_data.csv  \n",
            "  inflating: DataSet/Trial Data/taskC_trial_references.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f007f81f",
      "metadata": {
        "id": "f007f81f"
      },
      "source": [
        "## 1. General Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9ccbd48",
      "metadata": {
        "id": "f9ccbd48"
      },
      "source": [
        "Import some common libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e014b845",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e014b845",
        "outputId": "ac8a92c7-7a62-4a08-c071-c91b2b1a6446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "776d16fd",
      "metadata": {
        "id": "776d16fd"
      },
      "source": [
        "Use GPU Facilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "57c8f55c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57c8f55c",
        "outputId": "5c86a60d-8956-434a-fcf2-cf8df16768dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are using the device cuda:0 - Tesla P100-PCIE-16GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "cuda_id = 0\n",
        "device = torch.device(\"cuda:%s\" % cuda_id if torch.cuda.is_available() else \"cpu\")\n",
        "device_name = torch.cuda.get_device_name(cuda_id) if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"We are using the device %s - %s\" % (device, device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gWV7cy_EQ9iD"
      },
      "id": "gWV7cy_EQ9iD",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ee920058",
      "metadata": {
        "id": "ee920058"
      },
      "source": [
        "Set the model and hyperparameters for implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9e528bad",
      "metadata": {
        "id": "9e528bad"
      },
      "outputs": [],
      "source": [
        "# Best implementation\n",
        "model_name = \"roberta-large\"\n",
        "optimizer_name = 'Adam'\n",
        "learning_rate = 1e-5\n",
        "batch_size = 128\n",
        "epoch = 15\n",
        "\n",
        "# # Minor implementation\n",
        "# model_name = \"distilbert-base-uncased\"\n",
        "# optimizer_name = 'Adam'\n",
        "# learning_rate = 1e-5\n",
        "# batch_size = 8\n",
        "# epoch = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a07e7a0a",
      "metadata": {
        "id": "a07e7a0a"
      },
      "source": [
        "Set the path to save the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c8a18f2a",
      "metadata": {
        "id": "c8a18f2a"
      },
      "outputs": [],
      "source": [
        "model_params_path = \"./Subtask_A_Best_Model_.pth\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d008020f",
      "metadata": {
        "id": "d008020f"
      },
      "source": [
        "## 2. Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a6330a",
      "metadata": {
        "id": "b0a6330a"
      },
      "source": [
        "### 2.1 Read data from csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd9e9b83",
      "metadata": {
        "id": "fd9e9b83"
      },
      "source": [
        "Build a common function to get texts and labels from csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8f55f921",
      "metadata": {
        "id": "8f55f921"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def get_info_from_csv(texts_path, labels_path):\n",
        "    # texts1 = pd.read_csv(texts_path, header=0, names=['ID', 'sent0'])['sent0']\n",
        "    texts1 = pd.read_csv(texts_path)['sent0']\n",
        "    texts2 = pd.read_csv(texts_path)['sent1']\n",
        "    print(texts1[:5])\n",
        "    texts = pd.concat([texts1, texts2], axis=0)\n",
        "    labels1 = pd.read_csv(labels_path, header=None, names=['ID', 'Answer'])['Answer']\n",
        "    labels2 = pd.read_csv(labels_path, header=None, names=['ID', 'Answer'])['Answer'].replace((1, 0), (0, 1))\n",
        "    print(labels2[:5])\n",
        "    labels = pd.concat([labels1, labels2], axis=0)\n",
        "    return texts, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd701f67",
      "metadata": {
        "id": "cd701f67"
      },
      "source": [
        "Read texts and labels from csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f27166bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f27166bb",
        "outputId": "92af5421-7676-4b95-9712-3982b06486e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    He poured orange juice on his cereal.\n",
            "1                         He drinks apple.\n",
            "2                    Jeff ran a mile today\n",
            "3                     A mosquito stings me\n",
            "4                     A niece is a person.\n",
            "Name: sent0, dtype: object\n",
            "0    1\n",
            "1    1\n",
            "2    0\n",
            "3    0\n",
            "4    0\n",
            "Name: Answer, dtype: int64\n",
            "0    Summer in North America is great for skiing,  ...\n",
            "1              You can use detergent to dye your hair.\n",
            "2    passing your driving license exams requires st...\n",
            "3                        The hangers bought the closet\n",
            "4                                   coffee takes sleep\n",
            "Name: sent0, dtype: object\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: Answer, dtype: int64\n",
            "0          He loves to stroll at the park with his bed\n",
            "1        The inverter was able to power the continent.\n",
            "2              The chef put extra lemons on the pizza.\n",
            "3                    sugar is used to make coffee sour\n",
            "4    There are beautiful flowers here and there in ...\n",
            "Name: sent0, dtype: object\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: Answer, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "train_texts, train_labels = get_info_from_csv(\n",
        "    './DataSet/Training Data/subtaskA_data_all.csv',\n",
        "    './DataSet/Training Data/subtaskA_answers_all.csv'\n",
        ")\n",
        "\n",
        "val_texts, val_labels = get_info_from_csv(\n",
        "    './DataSet/Dev Data/subtaskA_dev_data.csv',\n",
        "    './DataSet/Dev Data/subtaskA_gold_answers.csv'\n",
        ")\n",
        "\n",
        "test_texts, test_labels = get_info_from_csv(\n",
        "    './DataSet/Test Data/subtaskA_test_data.csv',\n",
        "    './DataSet/Test Data/subtaskA_gold_answers.csv'\n",
        ")\n",
        "\n",
        "# Use the validation dataset as the training dataset\n",
        "train_texts = pd.concat([train_texts, val_texts], axis=0, ignore_index=True)\n",
        "train_labels = pd.concat([train_labels, val_labels], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2295ef05",
      "metadata": {
        "id": "2295ef05"
      },
      "source": [
        "Let's have a look at the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e78efc85",
      "metadata": {
        "id": "e78efc85"
      },
      "source": [
        "### 2.2 Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f184bc64",
      "metadata": {
        "id": "f184bc64"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizerFast, DistilBertTokenizerFast, RobertaTokenizerFast\n",
        "\n",
        "# Get tokenizer\n",
        "if model_name.startswith(\"bert\"):\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "elif model_name.startswith(\"distilbert\"):\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
        "elif model_name.startswith(\"roberta\"):\n",
        "    tokenizer = RobertaTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c22f01c",
      "metadata": {
        "id": "5c22f01c"
      },
      "source": [
        "### 2.3 Turn data into a Dataset object"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "054fbcda",
      "metadata": {
        "id": "054fbcda"
      },
      "source": [
        "Define a Dataset class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "bf33235b",
      "metadata": {
        "id": "bf33235b"
      },
      "outputs": [],
      "source": [
        "class ComVEDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7543974",
      "metadata": {
        "id": "e7543974"
      },
      "source": [
        "Turn encodings and labels into a Dataset object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "ac593e35",
      "metadata": {
        "id": "ac593e35"
      },
      "outputs": [],
      "source": [
        "# Turn encodings and labels into a Dataset object\n",
        "train_dataset = ComVEDataset(train_encodings, train_labels)\n",
        "# val_dataset = ComVEDataset(val_encodings, val_labels)\n",
        "test_dataset = ComVEDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6cb2166",
      "metadata": {
        "id": "a6cb2166"
      },
      "source": [
        "## 3. Loading the Model and Optimizer "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c7469416",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7469416",
        "outputId": "584ab886-c455-4709-b1c7-8d4dc97038e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, DistilBertForSequenceClassification, RobertaForSequenceClassification, AdamW\n",
        "\n",
        "# Loading the model\n",
        "if model_name.startswith(\"bert\"):\n",
        "    model = BertForSequenceClassification.from_pretrained(model_name)\n",
        "elif model_name.startswith(\"distilbert\"):\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
        "elif model_name.startswith(\"roberta\"):\n",
        "    model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
        "model.to(device)\n",
        "\n",
        "# Loading the optimizer\n",
        "if optimizer_name == \"Adam\":\n",
        "    optim = AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20779c40",
      "metadata": {
        "id": "20779c40"
      },
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c234e8c",
      "metadata": {
        "id": "9c234e8c"
      },
      "source": [
        "Prepare some utility functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "90e5439a",
      "metadata": {
        "id": "90e5439a"
      },
      "outputs": [],
      "source": [
        "# Prediction function\n",
        "def predict(outputs):\n",
        "    probabilities = torch.softmax(outputs[\"logits\"], dim=1)\n",
        "    # print(probabilities)\n",
        "    predictions = torch.argmax(probabilities, dim=1)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7674ee23",
      "metadata": {
        "id": "7674ee23"
      },
      "source": [
        "Train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "dd53a652",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dd53a652",
        "outputId": "349850de-92f1-44d1-f381-f004a4eca48e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/172 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 1185,   64,  304,   10, 8411,    7,  797,   10,  468, 9822,    2,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([  0, 250, 194,  16,  10, 737, 624,  10, 467,   2,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  8877, 12273,    10,  6777,    12, 23866,  1559,  3588,    13,\n",
            "            5,  2844,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  100,  342,   10, 2335,   15,  127,  471,    2,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  627, 1816, 4507,  159,   69, 5418,    7,   69, 3240, 2761,    2,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   100,   794,    10, 12094,  3051,    11,    10,  3907,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   170,   240,   514,    13,     5, 18906,     4,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   250, 32394,  2195,   782,  3778,     6,   514,     8,  6613,\n",
            "           11,   645,     7, 22056,     4,     2,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  100, 1017,  101,   10, 2931, 2418,    7,   33,   10,  357, 1217,\n",
            "           9,    5, 5252,    2,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 1185,   64,  304,  668,    7, 7142,    2,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 27850,    16,    10,  1468,    61,  6771,    10,   699,  2274,\n",
            "            9,  8720,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  2387,  2335, 11952,  3051,   127,   985,    15,    10,  2335,\n",
            "        32652,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  133,  674, 2608, 5181,   11, 5697,   16,  874, 4276, 4176,    2,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   102,  4692,  2168,   473,    45, 20189,   521,   108,   350,\n",
            "          203,    86,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  2387,  1141, 11952,  6970,    11,     5,  9310,     4,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 13584,  1150,    21,  9694,     6,  4634,    79,    16,  1818,\n",
            "           13,    10,   633,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  1106,    47,  1006,  4851,     6,    47,    74,    33,  1595,\n",
            "            5, 10743,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  4297,  1334, 37085,    64,  6966,    11,     5,   514,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   510,  9306,  2162,    10, 11720,  7014,     2,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 26302,  4048,    13,  9589,  3441,    86,     8,  1351,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   495,  5858, 21184,    11,     5,   159,  8443,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 24021,    16, 13897,    39,  2549,    19,  2480,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 38619,    16,    10,   182, 31429,  3477,     4,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 12861,  2195,   197,  4161,     7,   110,  1041,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  1185,    32,   533,     7,   465,    10, 14441,    11,    10,\n",
            "         4683,    11,     5,  1255,     4,     2,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  4992,   661,   710, 11574,    32,   205,    13,     5,  3024,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   133,   693, 24313,     5,  2335, 20987,   375,    63, 24833,\n",
            "         1248,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   100,   848,    10, 12062,  2350,     4,     2,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   170,    64,   304,     5,   418,     7,   907,   383,    11,\n",
            "            5, 12647,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  2716,    18,    33,    10, 17687,    23,     5, 14712,  6348,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  2515,  1224,    15,    69, 37390,     4,     2,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 8877, 1299, 4736,   98,   79,  439,    7,    5, 3299,    2,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  2515, 29716,    10,  2131, 16319,     4,     2,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   894,  1516, 20425,    71,  2929,   722,     9, 11152,   173,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  1106,    47,   218,    75,   236,     7,  2324,   383,    15,\n",
            "          110,   865,     6,   836,    10, 16907,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   133,  3778, 28159,  4520,    11,     5,   363,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  700,   21, 6432,   30,   39,  985,  142,   37,  399,   75,  892,\n",
            "         157,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   170,   240,    55,  4051,     7,   386,     5, 20212,     4,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   894,   342,    10, 11471,    11,    10,  1637,  9106,     4,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  894,  342,  514,   88,   10, 4049,    4,    2,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 7877, 7336,   33, 7656,  147,   47,   64,  465, 5274,    7,  110,\n",
            "        1142,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([  0, 118, 185, 799, 360, 160, 358, 186,   2,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  100,   64, 4161,    7,  643,  396, 1273,  127, 6085,    4,    2,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 12645,  4575,    32,   341,    13, 14978, 21459,   227,   383,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 4763,  218,   75,  240,    7, 4076,  514,    7,  697,    4,    2,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 2515,   21,  553,    7,  311,   69, 4576,   77,   79, 1381,    7,\n",
            "         907,   10, 3984,    2,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  1185,    40,   146,    55,   964,    30, 41142,   643,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   970,    32,  1117, 18979,    11,     5,  4118,   467,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   700,   875,    10,  1601,    15, 30016,     2,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 28151,   330,    16,  1104,    11,  3195,     2,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 43073,  1496,  7446,    64,  5393,   980,     2,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  4763,   197,  3529, 15646,     4,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   347, 10748,   281,  2333,   310,  4133,    77,     5,  4666,\n",
            "           32,   160,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  627, 2335, 2003, 2258,   70,  183,  251,    2,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 2515,  341,   69, 2335,    7, 1305,  409,   31,  343,    2,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  250, 3539, 1074,   11,    5,  514,    4,    2,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 33184,  1064,   159,     5, 16745,     8,  5932,    15,    39,\n",
            "          471,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  102, 1037,   16, 1062,    2,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   104,   459, 24320, 13866,   244, 14240,     2,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  8877, 23598,     7,     5,   930,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   894,   342,     5, 15162,    11,     5, 14974, 29370,     4,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   347,  1253,    64,  5585, 18833,  1025,     9,   106,     4,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 12645,  3006,   368,    16,    10,   761,     9,  8671,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 10285,   395,     6,   127,   284,   362,    10,  4293,   223,\n",
            "            5,  4908,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   133, 17082, 22941, 36269,   552,     5,   921,     4,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 44734,    32,     5,   144, 12038,  3122,    15,  6872,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   700, 24923,  2799,   358,   662,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   700,   269, 27701,  8942,     4, 12192,   123,   103,  4045,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   100,  4262,   239,   142, 17244,    16,   650,    13,   162,\n",
            "            4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 1185,  197,  120,   10, 1428, 4385,  114,   47,  236,    7, 1305,\n",
            "          10,  512,    4,    2,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  2515,  2037,    10,  2569,     6,    98,    79,   342,    15,\n",
            "           10, 11445,     7,  1877,  9592,    24,     7,   643,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  100,   64,  213,   66,  396, 2498,   10, 9540,    4,    2,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   133,  3778,  4976,   223,     5,  2335,     8,   362,    10,\n",
            "          765, 16159,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 8877, 8294,   15,   10, 3286, 5358,    2,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  894,   16, 6480,   15,    5, 8037,    2,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   250, 22443,  1690,  1033,   162,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  133, 3539, 3033,   23,    5, 2576,    9,    5, 3342,    4,    2,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   894,   342,    10, 23921,    88,     5,     7,  8831,     4,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 43047,   293,  6198,  1138,     2,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  100, 2162,  123,   10, 1040,    2,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 12350,    12,  3690,    82,    32,   686,     7,   465,  1315,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 44863,  4694,    33,     5,   276,  3024,  3195,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   133,   275,  2480,  6353, 24253,    16, 12041, 17712,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 28888,  3792,  3277,  3529,  4884,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 14696,  1073,  5023,    29,    64,  3529,  2440, 18018,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   894, 14964,     5,  8380,   137,  3723, 10244,    24,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   894,   794,    10, 45415,   150,  5796,    15,     5,  6964,\n",
            "         1245,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  9089, 37013, 14057,    16,   205,    13,   110,   474,     4,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 27735,  4728,    16,   182, 24042,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  133,  514,   31,    5, 9310,   16, 3279,    4,    2,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   133,  3333, 32311,    39,  2199,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   133,  4408,  1370,  5932,     5, 16847,     8,  9710,    10,\n",
            "         3814,  2058,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   347,  1529,  1942,    16,   156,    31,  3895, 13095,     4,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   894,   300,    11,    39, 11824, 30326,     7,   213,     7,\n",
            "          173,     4,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  2515, 24313, 15162, 10580,    31,    10, 37390,     4,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 1694,  342,    5, 6485,   11,  449, 4734, 2507,   77,   52,  213,\n",
            "         409,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  100, 1367,  127, 2473,  136,    5, 4520, 1109,    2,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   133,  8453,    16,    10, 33662,  4716,     4,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  133,  512,   21, 9181,   11,    5, 8247,    4,    2,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  4763,    54,  2217,  2408,   197,  3529,    55, 22127,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  4783, 36661,    21, 34441,    19,  5430,    77,    38,   439,\n",
            "          124,    71,   292,   728,     2,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   894,   342,     5,  4946,  4929,    88,     5, 20406,  2241,\n",
            "         3698,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  100, 1299, 5074,   77,  127, 1150, 1595,  409,    2,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  405,   18, 4940, 1522,    7, 1305,   71, 4835,    2,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 1185,  465,   10, 5518,  198,   11, 8140,    2,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   102,  2204,   396, 10238,     5,  1255,    16,  4703,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 14043, 18957,  5803,  2607,   408,  1733, 26647,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 2387, 2138,   16, 5523,   10,  633,    4,    2,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  1106,    47,   236,     7,  2217,  2408,     6,  3529, 15163,\n",
            "          689,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 24302,  9451, 35059,   817,   610,   619, 26722,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   133, 21495,  4840,    16,    10,  6587,   831,  4876,     4,\n",
            "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  118,  439,    7,    5, 3778,   77,  939,   21,  291,    2,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  1779,   951,  1974,     5, 21072,     6,    24,    16,    10,\n",
            "         8454,  1940,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 11107,   472,  3568,   765, 21764,     7,  2217,  2859,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 26621,   154,    16,    10,  4153,  2414,     4,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 2463, 6353,   16,  239,   11, 5886,    8, 4696,    2,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 1106,   47,  236,    7,  120,   10,  633,    6,   47,  531, 1532,\n",
            "          10, 6707,   78,    2,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  1185,    32,   533,     7,   465,    10,  7362,   443,    11,\n",
            "        14446,   558,     2,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 24940,    16, 25734,  9410,     2,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  2911,  4733,    32, 26643,     5,   935,  1881,   254,     2,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,  4763,   422,    15,   786,    12,   119, 33523,  1538,  7993,\n",
            "            4,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   700,  8144,    10,   790,    19,  4085, 44796,     2,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  100,   64,  517,   10, 7326, 2773,    4,    2,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0, 1594,   47,  236,    7,  517, 1769,    6,   47,  531,  422,    2,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0, 15117, 13300,  2630,    64, 12224,     2,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  243,   16, 1619,    6,   98,   38,  240,    7,  213, 3482,   13,\n",
            "        7420,    4,    2,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([    0,   243,    16,   533,    14,    79,    40,   120,    88,  2737,\n",
            "           19,    69,  1323,    11,     5,  7310, 10743,     2,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n",
            "--------------------------------------------------\n",
            "{'input_ids': tensor([   0,  894, 3829,    7, 3529,  103, 8942,   13, 7080,    4,    2,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/172 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8399a2b35f49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# count accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set the number of epoch\n",
        "epoch = epoch\n",
        "\n",
        "# Get training data by DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Start training\n",
        "model.train()\n",
        "\n",
        "train_loss = list()\n",
        "train_accuracies = list()\n",
        "highest_accuracy = 0\n",
        "for epoch_i in range(epoch):\n",
        "    print('Epoch %s/%s' % (epoch_i + 1, epoch))\n",
        "    time.sleep(0.3)\n",
        "    \n",
        "    correct = 0\n",
        "    count = 0\n",
        "    epoch_loss = list()\n",
        "    \n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch in pbar:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs['loss']\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        \n",
        "        # make predictions\n",
        "        predictions = predict(outputs)\n",
        "\n",
        "        # count accuracy\n",
        "        correct += predictions.eq(labels).sum().item()\n",
        "        count += len(labels)\n",
        "        accuracy = correct * 1.0 / count\n",
        "\n",
        "        # show progress along with metrics\n",
        "        pbar.set_postfix({\n",
        "            'Loss': '{:.3f}'.format(loss.item()),\n",
        "            'Accuracy': '{:.3f}'.format(accuracy)\n",
        "        })\n",
        "        \n",
        "        # record the loss for each batch\n",
        "        epoch_loss.append(loss.item())\n",
        "        \n",
        "    pbar.close()\n",
        "    \n",
        "    # record the loss and accuracy for each epoch\n",
        "    train_loss += epoch_loss\n",
        "    train_accuracies.append(accuracy)\n",
        "    \n",
        "    # save the model with the highest accuracy\n",
        "    if highest_accuracy < accuracy:\n",
        "        highest_accuracy = accuracy\n",
        "        torch.save(model.state_dict(), model_params_path) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e377d1be",
      "metadata": {
        "id": "e377d1be"
      },
      "source": [
        "Visualise the training loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "39f57a55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "39f57a55",
        "outputId": "5bb24acd-0d30-47e6-8965-d392f57035ec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Plot Iteration vs Training Loss\n",
        "plt.plot(train_loss, label=\"Training Loss\")\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Iteration vs Training Loss\")  \n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Epoch vs Training Accuracy\n",
        "acc_X = np.arange(len(train_accuracies))+1\n",
        "plt.plot(acc_X, train_accuracies,\"-\", label=\"Training Accuracy\")\n",
        "plt.xticks(acc_X)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Epoch vs Training Accuracy\")  \n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625db231",
      "metadata": {
        "id": "625db231"
      },
      "source": [
        "## 5. Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc1d95da",
      "metadata": {
        "id": "bc1d95da"
      },
      "source": [
        "## Manual Test\n",
        "Now, let's have a manual test on this trained model.  \n",
        "First, you need to input two statements that are similar but one is against common sense. Then, our trained model will predict which of the two statements is against common sense. In this way, we can check the performance of the model.  \n",
        "\n",
        "To perform a manual test, please run the following code block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8123879",
      "metadata": {
        "id": "a8123879"
      },
      "outputs": [],
      "source": [
        "\n",
        "manual_test = True\n",
        "count = 1\n",
        "while(manual_test):\n",
        "    print(\"Let's start our manual test.\\n\")\n",
        "    time.sleep(0.3)\n",
        "    \n",
        "    statement_1 = input(\"Please input your first statement (e.g. I drink milk.):\\n\")\n",
        "    statement_2 = input(\"Please input your second statement (e.g. Milk drinks me.):\\n\")\n",
        "\n",
        "    # Tokenization for two statements\n",
        "    # inputs = tokenizer(statement_1, statement_2, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
        "    inputs = tokenizer(statement_1, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Model makes its prediction\n",
        "    outputs = model(**inputs)\n",
        "    prediction = predict(outputs)\n",
        "    print(prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AUTOMATIC TEST**"
      ],
      "metadata": {
        "id": "TzaCgKxFp0Hl"
      },
      "id": "TzaCgKxFp0Hl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load the best-trained model\n",
        "model.load_state_dict(torch.load(model_params_path))\n",
        "\n",
        "# Get test data by DataLoader\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Start testing\n",
        "model.eval()\n",
        "\n",
        "counter = 0\n",
        "PATH = './generated_sentences.txt'\n",
        "with open(PATH) as f:\n",
        "  input_batch_txt = [line.rstrip('\\n').replace(',', '').replace('\\'','').replace('\\xa0', '') for line in f]\n",
        "  for statement in input_batch_txt:\n",
        "    # Tokenization for two statements\n",
        "    # inputs = tokenizer(statement_1, statement_2, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
        "    inputs = tokenizer(statement, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Model makes its prediction\n",
        "    outputs = model(**inputs)\n",
        "    # prediction = predict(outputs)\n",
        "    probabilities = torch.softmax(outputs[\"logits\"], dim=1)\n",
        "    predictions = torch.argmax(probabilities, dim=1)\n",
        "    # print(predictions)\n",
        "    if predictions==1:\n",
        "      counter += 1\n",
        "    else:\n",
        "      print(probabilities)\n",
        "      print(statement)\n",
        "\n",
        "  print(\"Generated annotations:\")\n",
        "  print(f\"Model predicted that {counter}/{len(input_batch_txt)} sentences are common sense.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfQTxhFqxn1r",
        "outputId": "395cb00a-266a-4701-920b-857d348c4710"
      },
      "id": "cfQTxhFqxn1r",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8619, 0.1381]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and suit took the read.\n",
            "tensor([[0.9829, 0.0171]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black in suits and suits took the bench.\n",
            "tensor([[0.9961, 0.0039]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit took the knife.\n",
            "tensor([[9.9972e-01, 2.7598e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and notebook took the suit.\n",
            "tensor([[0.9738, 0.0262]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and notebook took a pocket.\n",
            "tensor([[0.9465, 0.0535]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and notebook took a reading.\n",
            "tensor([[0.8889, 0.1111]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and notebook took the bench.\n",
            "tensor([[9.9908e-01, 9.2086e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and notebook took a tie.\n",
            "tensor([[9.9969e-01, 3.0743e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and notebook took a knife.\n",
            "tensor([[0.9399, 0.0601]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and pocket took the suit.\n",
            "tensor([[0.6662, 0.3338]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and pocket took a notebook.\n",
            "tensor([[0.9611, 0.0389]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and pocket took the pocket.\n",
            "tensor([[0.9910, 0.0090]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and pocket took a read.\n",
            "tensor([[0.9105, 0.0895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people in suits and pockets took the bench.\n",
            "tensor([[0.9355, 0.0645]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and pocket took a tie.\n",
            "tensor([[0.9557, 0.0443]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and pocket took the knife.\n",
            "tensor([[0.9659, 0.0341]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and read took the suit.\n",
            "tensor([[0.9792, 0.0208]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and read took a pocket.\n",
            "tensor([[0.9042, 0.0958]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and read took the read.\n",
            "tensor([[0.8910, 0.1090]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black in a suit and reading took the bench.\n",
            "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and read took a tie.\n",
            "tensor([[9.9979e-01, 2.1410e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and read took a knife.\n",
            "tensor([[9.9971e-01, 2.9309e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black in suits and bench took the suit.\n",
            "tensor([[9.9924e-01, 7.6310e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and bench took a notebook.\n",
            "tensor([[9.9954e-01, 4.6416e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and bench took a pocket.\n",
            "tensor([[9.9972e-01, 2.8265e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black in a suit and bench took a read.\n",
            "tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people in suits and benches took the bench.\n",
            "tensor([[9.9967e-01, 3.3192e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black in suits and benches took the book.\n",
            "tensor([[0.9985, 0.0015]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people in suits and benches took the booklet.\n",
            "tensor([[9.9971e-01, 2.9333e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black in a suit and bench took a tie.\n",
            "tensor([[9.9970e-01, 3.0152e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and bench took the knife.\n",
            "tensor([[9.9934e-01, 6.5603e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people in suits and books took the suit.\n",
            "tensor([[0.9523, 0.0477]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and book took a notebook.\n",
            "tensor([[0.9895, 0.0105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and book took a pocket.\n",
            "tensor([[0.8955, 0.1045]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people in suits and books took a read.\n",
            "tensor([[0.9395, 0.0605]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people in suits and books took the bench.\n",
            "tensor([[0.9889, 0.0111]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people in suits and books took the book.\n",
            "tensor([[0.7011, 0.2989]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and book took the booklet.\n",
            "tensor([[9.9931e-01, 6.8908e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and book took a tie.\n",
            "tensor([[9.9956e-01, 4.3813e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and book took the knife.\n",
            "tensor([[0.9982, 0.0018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and booklet took the suit.\n",
            "tensor([[0.9486, 0.0514]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and booklet took a notebook.\n",
            "tensor([[0.9857, 0.0143]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and booklet took a pocket.\n",
            "tensor([[0.9109, 0.0891]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and booklet took a read.\n",
            "tensor([[0.9981, 0.0019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and booklet took the bench.\n",
            "tensor([[0.9191, 0.0809]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and booklet took the book.\n",
            "tensor([[0.5964, 0.4036]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and booklet took the booklet.\n",
            "tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and booklet took a tie.\n",
            "tensor([[9.9976e-01, 2.4159e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and booklet took a knife.\n",
            "tensor([[0.5937, 0.4063]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and tie took a pocket.\n",
            "tensor([[0.9551, 0.0449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and tie took the read.\n",
            "tensor([[0.7501, 0.2499]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people in suits and ties took the bench.\n",
            "tensor([[0.9929, 0.0071]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the suit and tie took a knife.\n",
            "tensor([[9.9948e-01, 5.1531e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and suit took the suit.\n",
            "tensor([[0.9776, 0.0224]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and suit took the notebook.\n",
            "tensor([[0.9928, 0.0072]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and suit took a pocket.\n",
            "tensor([[0.9504, 0.0496]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and suit took a reading.\n",
            "tensor([[0.9967, 0.0033]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and suit took the bench.\n",
            "tensor([[0.9537, 0.0463]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and suit took the book.\n",
            "tensor([[0.7791, 0.2209]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and suit took the booklet.\n",
            "tensor([[9.9924e-01, 7.6161e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and suit took a tie.\n",
            "tensor([[9.9974e-01, 2.6229e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and suit took a knife.\n",
            "tensor([[9.9976e-01, 2.3741e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and person in the suit took off.\n",
            "tensor([[0.9977, 0.0023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebooks and notebooks were taken by the notebooks.\n",
            "tensor([[0.6919, 0.3081]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and the notebook took a pocket.\n",
            "tensor([[9.9981e-01, 1.9427e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebooks and people took the bench.\n",
            "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebooks and the black notebooks took the book.\n",
            "tensor([[0.9936, 0.0064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and notebook took the booklet.\n",
            "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and person in the tie took it.\n",
            "tensor([[9.9974e-01, 2.6320e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and the black notebook took a knife.\n",
            "tensor([[9.9974e-01, 2.6131e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and pocket took the suit.\n",
            "tensor([[0.8520, 0.1480]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and pocket takers the notebooks.\n",
            "tensor([[0.9512, 0.0488]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the notebook and pocket took the pocket.\n",
            "tensor([[0.8901, 0.1099]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and pocket took a read.\n",
            "tensor([[9.9962e-01, 3.8337e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and pocket took the bench.\n",
            "tensor([[9.9954e-01, 4.6380e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and pocket took the book.\n",
            "tensor([[0.5598, 0.4402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and pocket took the booklet.\n",
            "tensor([[9.9972e-01, 2.7860e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and pocket took a tie.\n",
            "tensor([[9.9944e-01, 5.6416e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the notebook and pocket took a knife.\n",
            "tensor([[9.9970e-01, 3.0168e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the suit with notebooks and readings.\n",
            "tensor([[0.9950, 0.0050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the bench notebooks and reading.\n",
            "tensor([[9.9975e-01, 2.5424e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took a tie with a notebook and a reading.\n",
            "tensor([[9.9970e-01, 2.9534e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the knife with notebooks and readings in.\n",
            "tensor([[9.9982e-01, 1.8002e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and bench took a suit.\n",
            "tensor([[9.9965e-01, 3.5448e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and bench took the notebook.\n",
            "tensor([[9.9978e-01, 2.2398e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and bench took a pocket.\n",
            "tensor([[0.5810, 0.4190]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with notebooks and a bench took a read.\n",
            "tensor([[9.9950e-01, 4.9839e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the book with notebooks and a bench.\n",
            "tensor([[9.9962e-01, 3.8208e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the booklet notebook and bench.\n",
            "tensor([[9.9967e-01, 3.3033e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with notebooks and a bench took a tie.\n",
            "tensor([[9.9974e-01, 2.6279e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the notebook and bench took a knife.\n",
            "tensor([[9.9965e-01, 3.5188e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with notebooks and books took a suit.\n",
            "tensor([[0.9963, 0.0037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the notebook and book took a pocket.\n",
            "tensor([[9.9947e-01, 5.2809e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the bench notebooks and books.\n",
            "tensor([[0.9719, 0.0281]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the book notebook and it was a.\n",
            "tensor([[9.9901e-01, 9.8509e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with notebooks and books took a tie.\n",
            "tensor([[9.9975e-01, 2.5236e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the knife with notebooks and books.\n",
            "tensor([[9.9975e-01, 2.4546e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the suit with notebooks and booklets.\n",
            "tensor([[0.9541, 0.0459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black notebook and booklet took the notebook.\n",
            "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the bench notebooks and booklets.\n",
            "tensor([[9.9978e-01, 2.2373e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took a tie with notebooks and booklets.\n",
            "tensor([[9.9952e-01, 4.7802e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took a knife notebooks and booklets.\n",
            "tensor([[9.9970e-01, 3.0381e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and tie took the suit.\n",
            "tensor([[0.9794, 0.0206]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the pocket with notebook and tie in hand.\n",
            "tensor([[0.9932, 0.0068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with notebook and tie took a reading.\n",
            "tensor([[0.9970, 0.0030]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the notebook and tie took the bench.\n",
            "tensor([[0.8395, 0.1605]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the booklet with notebook and tie in hand.\n",
            "tensor([[0.7746, 0.2254]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with notebook and tie took the tie.\n",
            "tensor([[9.9958e-01, 4.1887e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the knife with notebook and tie in hand.\n",
            "tensor([[0.8156, 0.1844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and suit takers the suit.\n",
            "tensor([[0.9823, 0.0177]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and suit person took a notebook.\n",
            "tensor([[0.6605, 0.3395]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and suit take the pocket.\n",
            "tensor([[0.9945, 0.0055]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the pocket and suit took a read.\n",
            "tensor([[9.9969e-01, 3.0737e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and suit took the bench.\n",
            "tensor([[0.9947, 0.0053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and suit person took the book.\n",
            "tensor([[0.9288, 0.0712]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and suit person took the booklet.\n",
            "tensor([[0.7979, 0.2021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and suit person took a tie.\n",
            "tensor([[0.9845, 0.0155]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the pocket and suit took the knife.\n",
            "tensor([[9.9960e-01, 3.9918e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and notebook takers the suit.\n",
            "tensor([[0.9850, 0.0150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and notebook takers the notebooks.\n",
            "tensor([[0.7460, 0.2540]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and notebook take the pocket.\n",
            "tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the pocket and notebook took a read.\n",
            "tensor([[9.9930e-01, 7.0316e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and notebook take the bench.\n",
            "tensor([[9.9905e-01, 9.5062e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the pocket and notebook took the book.\n",
            "tensor([[0.8975, 0.1025]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and notebook takers the booklet.\n",
            "tensor([[9.9963e-01, 3.7201e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and notebook take ties.\n",
            "tensor([[9.9977e-01, 2.3477e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the pocket and notebook took a knife.\n",
            "tensor([[0.7898, 0.2102]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and pocket people took the suit.\n",
            "tensor([[0.6217, 0.3783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and pocket people took a notebook.\n",
            "tensor([[0.7734, 0.2266]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and pocket people took the pocket.\n",
            "tensor([[9.9962e-01, 3.7810e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black in the pocket and pocket took a read.\n",
            "tensor([[9.9906e-01, 9.3996e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and pocket people took the bench.\n",
            "tensor([[0.9940, 0.0060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and pocket takers the book.\n",
            "tensor([[0.7270, 0.2730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and pocket people took the booklet.\n",
            "tensor([[0.9866, 0.0134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and pocket people took ties.\n",
            "tensor([[0.9975, 0.0025]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and pocket people took the knife.\n",
            "tensor([[9.9952e-01, 4.7646e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The pocket and read black took the suit.\n",
            "tensor([[0.9609, 0.0391]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and read person took a notebook.\n",
            "tensor([[9.9928e-01, 7.2318e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and reader took the pocket.\n",
            "tensor([[0.9964, 0.0036]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and read person took the read.\n",
            "tensor([[9.9934e-01, 6.5906e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and read person took the bench.\n",
            "tensor([[0.9954, 0.0046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and read person took the book.\n",
            "tensor([[0.9963, 0.0037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and read person took the booklet.\n",
            "tensor([[9.9932e-01, 6.7942e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The pocket and read black took a tie.\n",
            "tensor([[9.9952e-01, 4.7966e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and read person took the knife.\n",
            "tensor([[9.9963e-01, 3.6669e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The pocket and bench black took the suit.\n",
            "tensor([[9.9952e-01, 4.8391e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and bench person took the notebook.\n",
            "tensor([[9.9950e-01, 4.9837e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and bench people took the pocket.\n",
            "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and bench people took a read.\n",
            "tensor([[0.9974, 0.0026]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and bench people took the bench.\n",
            "tensor([[9.9959e-01, 4.0720e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and bench person took the book.\n",
            "tensor([[9.9916e-01, 8.3686e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and bench people took the booklet.\n",
            "tensor([[9.9956e-01, 4.3532e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and bench person took a tie.\n",
            "tensor([[9.9967e-01, 3.2612e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and bench person took the knife.\n",
            "tensor([[9.9971e-01, 2.8688e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The pocket and book black people took the suit.\n",
            "tensor([[0.9364, 0.0636]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and book takers a notebook.\n",
            "tensor([[0.7559, 0.2441]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and book takers the pocket.\n",
            "tensor([[0.6716, 0.3284]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with pockets and books took a read.\n",
            "tensor([[9.9947e-01, 5.2654e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and book thief took the bench.\n",
            "tensor([[0.8433, 0.1567]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the pocket and book took the book.\n",
            "tensor([[0.9755, 0.0245]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and book takers the booklet.\n",
            "tensor([[9.9944e-01, 5.5983e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and book holder took a tie.\n",
            "tensor([[0.9886, 0.0114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and book thief took a knife.\n",
            "tensor([[9.9966e-01, 3.4230e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and booklet takers the suit.\n",
            "tensor([[0.9706, 0.0294]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and booklet takers a notebook.\n",
            "tensor([[9.9965e-01, 3.5296e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the pocket and booklet took a read.\n",
            "tensor([[9.9956e-01, 4.3590e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and booklet takers to the bench.\n",
            "tensor([[0.7796, 0.2204]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the booklet pocket and booklet.\n",
            "tensor([[9.9960e-01, 3.9538e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and booklet holders took ties.\n",
            "tensor([[9.9914e-01, 8.5689e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the knife pocket and booklet.\n",
            "tensor([[0.6423, 0.3577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and tie took the suit.\n",
            "tensor([[9.9958e-01, 4.1830e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and tie took a notebook.\n",
            "tensor([[0.9642, 0.0358]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and tie took the pocket.\n",
            "tensor([[9.9970e-01, 3.0384e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and tie took a read.\n",
            "tensor([[9.9972e-01, 2.8463e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and tie took the bench.\n",
            "tensor([[9.9975e-01, 2.5463e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and tie took the book.\n",
            "tensor([[9.9912e-01, 8.7692e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and tie took the booklet.\n",
            "tensor([[0.7455, 0.2545]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and tie took the tie.\n",
            "tensor([[9.9969e-01, 3.0850e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black pocket and tie took the knife.\n",
            "tensor([[9.9975e-01, 2.4572e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and suit took the suit.\n",
            "tensor([[9.9955e-01, 4.4574e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and suit took a notebook.\n",
            "tensor([[9.9915e-01, 8.4513e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and suit took a pocket.\n",
            "tensor([[9.9959e-01, 4.1112e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and suit took the read.\n",
            "tensor([[9.9954e-01, 4.5852e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and suit took the bench.\n",
            "tensor([[9.9973e-01, 2.6959e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and suit took the book.\n",
            "tensor([[9.9962e-01, 3.7888e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and suit took the booklet.\n",
            "tensor([[9.9917e-01, 8.2616e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the reading and suit took a tie.\n",
            "tensor([[9.9981e-01, 1.9441e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and suit took a knife.\n",
            "tensor([[9.9974e-01, 2.5782e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and notebook took a suit.\n",
            "tensor([[0.9722, 0.0278]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and notebook took a notebook.\n",
            "tensor([[0.9858, 0.0142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and notebook took a pocket.\n",
            "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and notebook took a read.\n",
            "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and notebook took the bench.\n",
            "tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and notebook took the book.\n",
            "tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and notebook took the booklet.\n",
            "tensor([[9.9971e-01, 2.8615e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and notebook took a tie.\n",
            "tensor([[9.9980e-01, 2.0159e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and notebook took a knife.\n",
            "tensor([[9.9972e-01, 2.7627e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and pocket took the suit.\n",
            "tensor([[9.9939e-01, 6.1288e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and pocket took a notebook.\n",
            "tensor([[9.9928e-01, 7.2503e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the read and pocket took the pocket.\n",
            "tensor([[9.9922e-01, 7.8117e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and pocket took the read.\n",
            "tensor([[9.9972e-01, 2.7961e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and pocket took the bench.\n",
            "tensor([[0.9930, 0.0070]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and pocket-sized took the book.\n",
            "tensor([[9.9914e-01, 8.5884e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and pocket took the booklet.\n",
            "tensor([[9.9977e-01, 2.3110e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and pocket took a tie.\n",
            "tensor([[9.9966e-01, 3.3692e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and pocketie took a knife.\n",
            "tensor([[9.9970e-01, 3.0037e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader takes a suit.\n",
            "tensor([[9.9967e-01, 3.2753e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader took a pocket.\n",
            "tensor([[0.8780, 0.1220]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Black readers take reading.\n",
            "tensor([[0.9763, 0.0237]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black read and read people took the bench.\n",
            "tensor([[9.9970e-01, 2.9701e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader takes a tie.\n",
            "tensor([[9.9976e-01, 2.4093e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader took a knife.\n",
            "tensor([[9.9976e-01, 2.3708e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and bench took a suit.\n",
            "tensor([[9.9971e-01, 2.8954e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and bench took a notebook.\n",
            "tensor([[9.9978e-01, 2.2255e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and bench took a pocket.\n",
            "tensor([[9.9958e-01, 4.1686e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black read and bench people took the read.\n",
            "tensor([[9.9968e-01, 3.1669e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and bench took the bench.\n",
            "tensor([[9.9959e-01, 4.0722e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and bench took the book.\n",
            "tensor([[9.9956e-01, 4.4172e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and bench took the booklet.\n",
            "tensor([[9.9978e-01, 2.1911e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and bench took a tie.\n",
            "tensor([[9.9981e-01, 1.9427e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and bench took a knife.\n",
            "tensor([[9.9979e-01, 2.0917e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and book took a suit.\n",
            "tensor([[0.9981, 0.0019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and book took a notebook.\n",
            "tensor([[0.9969, 0.0031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and book took a pocket.\n",
            "tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and book took the bench.\n",
            "tensor([[9.9980e-01, 1.9884e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and book took a tie.\n",
            "tensor([[9.9982e-01, 1.7633e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and book took a knife.\n",
            "tensor([[9.9978e-01, 2.1684e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and booklet took a suit.\n",
            "tensor([[9.9907e-01, 9.2708e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and booklet took a notebook.\n",
            "tensor([[0.9975, 0.0025]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and booklet took a pocket.\n",
            "tensor([[9.9944e-01, 5.5681e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and booklet took a read.\n",
            "tensor([[9.9968e-01, 3.2027e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and booklet took the bench.\n",
            "tensor([[0.9976, 0.0024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Black readers and booklets take books.\n",
            "tensor([[9.9980e-01, 2.0468e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and booklet took a tie.\n",
            "tensor([[9.9981e-01, 1.8606e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and booklet took a knife.\n",
            "tensor([[0.5858, 0.4142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the readies and tie took the suit.\n",
            "tensor([[9.9958e-01, 4.1513e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and tie took a notebook.\n",
            "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and tie took a pocket.\n",
            "tensor([[0.9919, 0.0081]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the read and tie took the read.\n",
            "tensor([[0.9844, 0.0156]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the reading and tie took the bench.\n",
            "tensor([[9.9950e-01, 5.0314e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and tie took the book.\n",
            "tensor([[9.9907e-01, 9.2830e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and tie took the booklet.\n",
            "tensor([[9.9965e-01, 3.5246e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and tie took the tie.\n",
            "tensor([[9.9980e-01, 1.9931e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black reader and tie took a knife.\n",
            "tensor([[9.9959e-01, 4.0650e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and suit took the suit.\n",
            "tensor([[9.9978e-01, 2.2209e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and suit took a notebook.\n",
            "tensor([[9.9948e-01, 5.1909e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and suit took a pocket.\n",
            "tensor([[9.9949e-01, 5.1090e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and suit person took a read.\n",
            "tensor([[9.9980e-01, 1.9964e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench was taken by a black person in a bench and suit.\n",
            "tensor([[9.9961e-01, 3.8685e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and suit people took the book.\n",
            "tensor([[9.9983e-01, 1.6824e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and suit take the booklet.\n",
            "tensor([[9.9957e-01, 4.3235e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench and suit blacks took ties.\n",
            "tensor([[9.9975e-01, 2.5327e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the bench and suit took a knife.\n",
            "tensor([[9.9982e-01, 1.8370e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and notebook took the suit.\n",
            "tensor([[0.8751, 0.1249]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and notebook took the notebook.\n",
            "tensor([[9.9971e-01, 2.9271e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and notebook took a pocket.\n",
            "tensor([[0.9741, 0.0259]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and notebook took a read.\n",
            "tensor([[9.9916e-01, 8.4412e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the bench and notebook took it.\n",
            "tensor([[9.9969e-01, 3.1218e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the book taking the bench and notebook.\n",
            "tensor([[9.9980e-01, 1.9904e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and notebook took a tie.\n",
            "tensor([[9.9983e-01, 1.6921e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and notebook took a knife.\n",
            "tensor([[9.9967e-01, 3.3162e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and pocket people took the suit.\n",
            "tensor([[0.9989, 0.0011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and pocket people took a notebook.\n",
            "tensor([[9.9910e-01, 8.9796e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and pocket people took the pocket.\n",
            "tensor([[9.9942e-01, 5.7735e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and pocket took a read.\n",
            "tensor([[9.9974e-01, 2.5685e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench was taken by a black person with a bench and pocket.\n",
            "tensor([[0.9950, 0.0050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and pocket took the book.\n",
            "tensor([[9.9967e-01, 3.2751e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and pocket took the booklet.\n",
            "tensor([[9.9936e-01, 6.4307e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and pocket people took ties.\n",
            "tensor([[9.9978e-01, 2.1809e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and pocket took the knife.\n",
            "tensor([[9.9971e-01, 2.8686e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench and read were black taking on the suit.\n",
            "tensor([[9.9965e-01, 3.5310e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and read person took a pocket.\n",
            "tensor([[9.9964e-01, 3.6070e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and read took the read.\n",
            "tensor([[9.9978e-01, 2.2473e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench was taken by a black bench and read.\n",
            "tensor([[9.9968e-01, 3.2464e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and reader took the book.\n",
            "tensor([[9.9954e-01, 4.6251e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and reader took the booklet.\n",
            "tensor([[9.9978e-01, 2.2090e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and read took a tie.\n",
            "tensor([[9.9977e-01, 2.3267e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and read took a knife.\n",
            "tensor([[0.9691, 0.0309]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench and bench blacks took a suit.\n",
            "tensor([[0.9876, 0.0124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and bench people took a notebook.\n",
            "tensor([[9.9968e-01, 3.1525e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and bench people took a pocket.\n",
            "tensor([[0.9933, 0.0067]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and bench people took a read.\n",
            "tensor([[0.9552, 0.0448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench was taken by a black bench and bench.\n",
            "tensor([[0.5165, 0.4835]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and bench people took the book.\n",
            "tensor([[0.7282, 0.2718]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and bench people took the booklet.\n",
            "tensor([[9.9911e-01, 8.8840e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench and bench blacks took ties.\n",
            "tensor([[9.9956e-01, 4.4454e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench and bench blacks took a knife.\n",
            "tensor([[9.9964e-01, 3.6409e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and book takers a suit.\n",
            "tensor([[0.9549, 0.0451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and the book took a notebook.\n",
            "tensor([[9.9941e-01, 5.9223e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and book took a pocket.\n",
            "tensor([[0.9795, 0.0205]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people on the bench and books took a read.\n",
            "tensor([[9.9972e-01, 2.7745e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people on the bench and the book took the bench.\n",
            "tensor([[0.8927, 0.1073]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people on the bench and the books took the book.\n",
            "tensor([[0.8357, 0.1643]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and the book took the booklet.\n",
            "tensor([[9.9981e-01, 1.8610e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and book took a tie.\n",
            "tensor([[9.9981e-01, 1.8564e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and the book took a knife.\n",
            "tensor([[9.9982e-01, 1.7657e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and booklet took the suit.\n",
            "tensor([[0.9756, 0.0244]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and booklet took a notebook.\n",
            "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and booklet took a pocket.\n",
            "tensor([[0.9976, 0.0024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people on the bench and booklet took a read.\n",
            "tensor([[9.9956e-01, 4.3627e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench was taken by a black person with the bench and booklet.\n",
            "tensor([[0.9721, 0.0279]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and booklet took the book.\n",
            "tensor([[0.9920, 0.0080]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black people on the bench and booklet took the booklet.\n",
            "tensor([[9.9967e-01, 3.2593e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and booklet took a tie.\n",
            "tensor([[9.9984e-01, 1.6457e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person on the bench and booklet took a knife.\n",
            "tensor([[9.9971e-01, 2.9226e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench and tie black took the suit.\n",
            "tensor([[9.9980e-01, 1.9550e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and tie took a notebook.\n",
            "tensor([[9.9974e-01, 2.5759e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and tie took a pocket.\n",
            "tensor([[9.9979e-01, 2.1146e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and tie took a read.\n",
            "tensor([[9.9981e-01, 1.9054e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench was taken by a black bench and tie.\n",
            "tensor([[9.9985e-01, 1.5462e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and tie took the book.\n",
            "tensor([[9.9984e-01, 1.5679e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and tie took the booklet.\n",
            "tensor([[9.9924e-01, 7.6443e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The bench and tie blacks took the tie.\n",
            "tensor([[9.9980e-01, 1.9528e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black bench and tie took a knife.\n",
            "tensor([[0.9876, 0.0124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the book and suit took the suit.\n",
            "tensor([[0.9948, 0.0052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the book and suit took a notebook.\n",
            "tensor([[9.9946e-01, 5.3895e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the book and suit took a pocket.\n",
            "tensor([[9.9931e-01, 6.8551e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black in the book and suit took the bench.\n",
            "tensor([[0.9818, 0.0182]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the book and suit took the book.\n",
            "tensor([[0.9824, 0.0176]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the book and suit took the booklet.\n",
            "tensor([[0.9867, 0.0133]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the book and suit took a tie.\n",
            "tensor([[9.9972e-01, 2.8109e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the book and suit took a knife.\n",
            "tensor([[9.9976e-01, 2.4349e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and notebook took the suit.\n",
            "tensor([[0.9951, 0.0049]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and notebook took a pocket.\n",
            "tensor([[0.9989, 0.0011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and notebook took the bench.\n",
            "tensor([[0.9950, 0.0050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and notebook took the booklet.\n",
            "tensor([[9.9980e-01, 2.0185e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and notebook took a tie.\n",
            "tensor([[9.9960e-01, 4.0387e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the knife with the book and notebook.\n",
            "tensor([[0.9972, 0.0028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and pocket person took the suit.\n",
            "tensor([[0.9850, 0.0150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and pocket takers a notebook.\n",
            "tensor([[0.9589, 0.0411]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the books and pockets took the pocket.\n",
            "tensor([[0.5127, 0.4873]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the book and pocket took a read.\n",
            "tensor([[9.9939e-01, 6.1300e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and pocket people took the bench.\n",
            "tensor([[0.9922, 0.0078]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and pocket takers took the booklet.\n",
            "tensor([[9.9921e-01, 7.9323e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and pocket person took a tie.\n",
            "tensor([[9.9963e-01, 3.6670e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the knife with books and pockets.\n",
            "tensor([[9.9967e-01, 3.3035e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and reader took a suit.\n",
            "tensor([[0.9739, 0.0261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and reader took a notebook.\n",
            "tensor([[9.9956e-01, 4.3841e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and reader took a pocket.\n",
            "tensor([[0.9691, 0.0309]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Black book and reader take a read.\n",
            "tensor([[9.9959e-01, 4.1281e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and reader took the bench.\n",
            "tensor([[0.9863, 0.0137]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Black book and reader take books.\n",
            "tensor([[9.9976e-01, 2.3847e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and reader took a tie.\n",
            "tensor([[9.9978e-01, 2.2385e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and reader took a knife.\n",
            "tensor([[9.9963e-01, 3.7243e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The book and bench blacks took the suit.\n",
            "tensor([[0.9875, 0.0125]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and bench people took a notebook.\n",
            "tensor([[9.9963e-01, 3.7196e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and bench person took a pocket.\n",
            "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and bench people took a read.\n",
            "tensor([[0.9923, 0.0077]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and bench people took the bench.\n",
            "tensor([[9.9970e-01, 2.9568e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The book and bench blacks took it.\n",
            "tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and bench people took the booklet.\n",
            "tensor([[9.9972e-01, 2.7837e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and bench people took ties.\n",
            "tensor([[9.9975e-01, 2.4556e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and bench person took a knife.\n",
            "tensor([[0.9800, 0.0200]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and book people took the suit.\n",
            "tensor([[9.9926e-01, 7.3973e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the books and the books took the pocket.\n",
            "tensor([[0.9907, 0.0093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and book people took the bench.\n",
            "tensor([[0.9954, 0.0046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Blacks take books.\n",
            "tensor([[9.9927e-01, 7.3088e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The book and book blacks took ties.\n",
            "tensor([[9.9974e-01, 2.5812e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The book and book blacks took a knife.\n",
            "tensor([[9.9982e-01, 1.7563e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and booklet people took the suit.\n",
            "tensor([[0.9715, 0.0285]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and booklet takers a notebook.\n",
            "tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and booklet takers are in pockets.\n",
            "tensor([[0.8987, 0.1013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and booklet takers read.\n",
            "tensor([[9.9981e-01, 1.9105e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and booklet people took the bench.\n",
            "tensor([[0.6597, 0.3403]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The book and booklet are taken by black people.\n",
            "tensor([[9.9975e-01, 2.4834e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and booklet people took ties.\n",
            "tensor([[9.9983e-01, 1.7365e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black book and booklet people took a knife.\n",
            "tensor([[9.9958e-01, 4.1810e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the book and tie took the suit.\n",
            "tensor([[0.9887, 0.0113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the book and tie took a pocket.\n",
            "tensor([[0.8050, 0.1950]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the book and tie took a read.\n",
            "tensor([[0.9972, 0.0028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the book and tie took the bench.\n",
            "tensor([[0.9974, 0.0026]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the book and tie took the book.\n",
            "tensor([[0.8636, 0.1364]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the book and tie took the booklet.\n",
            "tensor([[0.9973, 0.0027]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the book and tie took the tie.\n",
            "tensor([[9.9971e-01, 2.9352e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the book and tie took a knife.\n",
            "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the booklet and suit took the suit.\n",
            "tensor([[0.9893, 0.0107]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the booklet and suit took a notebook.\n",
            "tensor([[9.9911e-01, 8.9257e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the booklet and suit took a pocket.\n",
            "tensor([[0.9381, 0.0619]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the booklet and suit took a read.\n",
            "tensor([[9.9958e-01, 4.2178e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the booklet and suit took the bench.\n",
            "tensor([[0.9958, 0.0042]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the booklet and suit took the book.\n",
            "tensor([[0.9832, 0.0168]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the booklet and suit took the booklet.\n",
            "tensor([[9.9917e-01, 8.2751e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the booklet and suit took a tie.\n",
            "tensor([[9.9977e-01, 2.2889e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the booklet and suit took a knife.\n",
            "tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the suit with the booklet and notebook.\n",
            "tensor([[0.9978, 0.0022]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the bench booklets and notebooks.\n",
            "tensor([[9.9974e-01, 2.6231e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took a tie with booklets and notebooks.\n",
            "tensor([[9.9976e-01, 2.3972e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the knife with booklets and notebooks.\n",
            "tensor([[9.9972e-01, 2.7966e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the booklet and pocket took the suit.\n",
            "tensor([[0.9447, 0.0553]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the booklet and pocket took the pocket.\n",
            "tensor([[9.9969e-01, 3.0544e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the bench booklets and pockets.\n",
            "tensor([[0.9953, 0.0047]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the booklet took the pocket and booklet.\n",
            "tensor([[0.9972, 0.0028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the tie with the booklet and pocket.\n",
            "tensor([[9.9971e-01, 2.8928e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the knife with booklets and pockets.\n",
            "tensor([[9.9972e-01, 2.8334e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the booklet and reading took the suit.\n",
            "tensor([[9.9979e-01, 2.0980e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the bench is the booklet and the reader.\n",
            "tensor([[0.5185, 0.4815]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Black book-readers take it.\n",
            "tensor([[0.9976, 0.0024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the tie took the booklet and read.\n",
            "tensor([[9.9976e-01, 2.3627e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the booklet and reading took a knife.\n",
            "tensor([[9.9978e-01, 2.2335e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the booklet and bench took the suit.\n",
            "tensor([[0.9979, 0.0021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the booklet and bench took a notebook.\n",
            "tensor([[9.9931e-01, 6.9461e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the booklet and bench took a pocket.\n",
            "tensor([[0.9644, 0.0356]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the booklet and the bench took a read.\n",
            "tensor([[9.9978e-01, 2.1771e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the bench is the booklet and bench.\n",
            "tensor([[9.9973e-01, 2.7150e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the booklet and the bench took the book.\n",
            "tensor([[0.9936, 0.0064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The booklets were taken by black people with the booklets and the benches.\n",
            "tensor([[9.9974e-01, 2.5661e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the booklet and bench took a tie.\n",
            "tensor([[9.9977e-01, 2.3305e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the booklet and bench took a knife.\n",
            "tensor([[9.9971e-01, 2.8770e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the booklet and the book took a suit.\n",
            "tensor([[0.6947, 0.3053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the booklet and the book took a notebook.\n",
            "tensor([[0.9976, 0.0024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the booklets and books took a pocket.\n",
            "tensor([[9.9902e-01, 9.8278e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the tie took the booklet and book.\n",
            "tensor([[9.9953e-01, 4.7375e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the booklet and the book took a knife.\n",
            "tensor([[9.9964e-01, 3.5739e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the booklet and booklet took the suit.\n",
            "tensor([[0.6589, 0.3411]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person taking the booklets and booklets to the bench.\n",
            "tensor([[9.9971e-01, 2.8767e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The booklet and booklet black people took ties.\n",
            "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person in the booklet and tie took a suit.\n",
            "tensor([[0.9822, 0.0178]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the notebook booklet and tie.\n",
            "tensor([[0.8035, 0.1965]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the pocket with booklet and tie in black.\n",
            "tensor([[0.9989, 0.0011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person took the bench with booklet and tie in hand.\n",
            "tensor([[0.7200, 0.2800]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the booklet and tie took the book.\n",
            "tensor([[0.5358, 0.4642]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the booklet and tie took the booklet.\n",
            "tensor([[0.6968, 0.3032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the booklet and tie took the tie.\n",
            "tensor([[9.9972e-01, 2.8444e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The black person with the booklet and tie took a knife.\n",
            "tensor([[9.9959e-01, 4.1341e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and suits take notebooks.\n",
            "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and suits take a read.\n",
            "tensor([[0.9916, 0.0084]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and suits take the bench.\n",
            "tensor([[0.9012, 0.0988]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and suits take the book.\n",
            "tensor([[9.9960e-01, 3.9683e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and suits take knives.\n",
            "tensor([[9.9977e-01, 2.2781e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and notebooks take suits.\n",
            "tensor([[9.9938e-01, 6.1635e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People in suits and notebooks took pockets.\n",
            "tensor([[0.9977, 0.0023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People in suits and notebooks took a read.\n",
            "tensor([[9.9927e-01, 7.3486e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The people in suits and notebooks took the bench.\n",
            "tensor([[0.9850, 0.0150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The person who looked in a suit and a notebook took the book.\n",
            "tensor([[9.9957e-01, 4.3160e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The person who looked in the suit and notebook took the booklet.\n",
            "tensor([[9.9974e-01, 2.5627e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People in suits and notebooks took ties.\n",
            "tensor([[9.9973e-01, 2.6950e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The person in the suit and notebook took a knife.\n",
            "tensor([[0.9940, 0.0060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and pockets take a read.\n",
            "tensor([[9.9961e-01, 3.9044e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and pockets take the bench.\n",
            "tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and pockets take books.\n",
            "tensor([[0.9972, 0.0028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and pockets take knives.\n",
            "tensor([[0.7769, 0.2231]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and read take suits.\n",
            "tensor([[0.9892, 0.0108]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and read take a notebook.\n",
            "tensor([[0.9574, 0.0426]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The person looking in a suit and reading takes the pocket.\n",
            "tensor([[0.9977, 0.0023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The people who looked in suits and read took the bench.\n",
            "tensor([[0.9982, 0.0018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and read take ties.\n",
            "tensor([[9.9969e-01, 3.0945e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and read take knives.\n",
            "tensor([[0.7280, 0.2720]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and on the bench take suits.\n",
            "tensor([[0.9981, 0.0019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The person who looked in a suit and on a bench took a notebook.\n",
            "tensor([[9.9946e-01, 5.3981e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and benches take pockets.\n",
            "tensor([[0.9970, 0.0030]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and on the bench take a read.\n",
            "tensor([[9.9902e-01, 9.8108e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and benches take the bench.\n",
            "tensor([[9.9934e-01, 6.5788e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and on the bench take the book.\n",
            "tensor([[9.9982e-01, 1.7881e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking for a suit and bench take the booklet.\n",
            "tensor([[9.9904e-01, 9.6491e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and benched take ties.\n",
            "tensor([[9.9977e-01, 2.2991e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and on benches take knives.\n",
            "tensor([[0.9959, 0.0041]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and books take suits.\n",
            "tensor([[0.9900, 0.0100]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and books take notebooks.\n",
            "tensor([[0.9981, 0.0019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The person who looked in a suit and a book took a pocket.\n",
            "tensor([[0.5432, 0.4568]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and books take a read.\n",
            "tensor([[9.9913e-01, 8.7007e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The people who looked in suits and books took the bench.\n",
            "tensor([[0.9796, 0.0204]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and books take books.\n",
            "tensor([[0.9764, 0.0236]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and books take booklets.\n",
            "tensor([[0.9961, 0.0039]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and books take ties.\n",
            "tensor([[9.9975e-01, 2.4774e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and books take knives.\n",
            "tensor([[0.9238, 0.0762]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at suits and booklets take their suits.\n",
            "tensor([[9.9902e-01, 9.7834e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and booklets take a notebook.\n",
            "tensor([[9.9909e-01, 9.0824e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and booklets take their pockets.\n",
            "tensor([[0.9735, 0.0265]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and booklets take a read.\n",
            "tensor([[9.9966e-01, 3.3857e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and booklets take the bench.\n",
            "tensor([[0.9985, 0.0015]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at suits and booklets take the book.\n",
            "tensor([[0.9738, 0.0262]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and booklets take the booklet.\n",
            "tensor([[9.9970e-01, 2.9588e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People in suits and booklets take ties.\n",
            "tensor([[9.9978e-01, 2.1703e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and booklets take knives.\n",
            "tensor([[0.9965, 0.0035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People in suits and ties take a read.\n",
            "tensor([[0.9944, 0.0056]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People in suits and ties took to the bench.\n",
            "tensor([[0.9970, 0.0030]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in suits and ties take the book.\n",
            "tensor([[9.9954e-01, 4.6220e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People in suits and ties took knives.\n",
            "tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and suits take suits.\n",
            "tensor([[0.9930, 0.0070]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in notebooks and suits take notes.\n",
            "tensor([[9.9925e-01, 7.4680e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look like notebooks and suits take their pockets.\n",
            "tensor([[9.9970e-01, 2.9695e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and suits take a read.\n",
            "tensor([[9.9977e-01, 2.2838e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who looked in notebooks and suits took to the bench.\n",
            "tensor([[0.9982, 0.0018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and suits take books.\n",
            "tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who looked at notebooks and suits took booklets.\n",
            "tensor([[9.9972e-01, 2.8416e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People in notebooks and suits took ties.\n",
            "tensor([[9.9980e-01, 1.9857e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who looked at notebooks and suits took knives.\n",
            "tensor([[9.9982e-01, 1.8126e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and notebooks take a suit.\n",
            "tensor([[0.7539, 0.2461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and notebooks take them into pockets.\n",
            "tensor([[0.9982, 0.0018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and notebooks take the bench.\n",
            "tensor([[9.9955e-01, 4.5431e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and notebooks take ties.\n",
            "tensor([[9.9977e-01, 2.3141e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and notebooks take knives.\n",
            "tensor([[9.9956e-01, 4.3599e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and pockets take a suit.\n",
            "tensor([[0.5260, 0.4740]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and pockets take them out of the pocket.\n",
            "tensor([[9.9938e-01, 6.2147e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at notebooks and pockets took a bench.\n",
            "tensor([[0.9960, 0.0040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and pockets take books.\n",
            "tensor([[0.7841, 0.2159]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and pockets take booklets.\n",
            "tensor([[9.9954e-01, 4.5501e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and pockets take ties.\n",
            "tensor([[9.9978e-01, 2.1739e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at notebooks and pockets took a knife.\n",
            "tensor([[9.9967e-01, 3.2954e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and read take a suit.\n",
            "tensor([[0.7672, 0.2328]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and read take them into pockets.\n",
            "tensor([[0.9832, 0.0168]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and read take the bench.\n",
            "tensor([[9.9937e-01, 6.2923e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and read take ties.\n",
            "tensor([[9.9975e-01, 2.4609e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and read take a knife.\n",
            "tensor([[9.9981e-01, 1.9217e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at notebooks and benches took a suit.\n",
            "tensor([[9.9919e-01, 8.0893e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at notebooks and benches took notes.\n",
            "tensor([[9.9971e-01, 2.8998e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at notebooks and benches took a pocket.\n",
            "tensor([[0.9982, 0.0018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and benches take a read.\n",
            "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and benches take the bench.\n",
            "tensor([[9.9919e-01, 8.1324e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and benches take books.\n",
            "tensor([[0.9981, 0.0019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and benches take booklets.\n",
            "tensor([[9.9979e-01, 2.1050e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at notebooks and benches took ties.\n",
            "tensor([[9.9980e-01, 2.0486e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at notebooks and benches took knives.\n",
            "tensor([[9.9976e-01, 2.4363e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and books take a suit.\n",
            "tensor([[0.9949, 0.0051]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and books take them into pockets.\n",
            "tensor([[0.9942, 0.0058]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and books take the bench.\n",
            "tensor([[9.9961e-01, 3.9085e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and books take ties.\n",
            "tensor([[9.9976e-01, 2.3860e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and books take knives.\n",
            "tensor([[9.9919e-01, 8.0539e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and booklets take suits.\n",
            "tensor([[0.9586, 0.0414]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and booklets take them into pockets.\n",
            "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who looked through notebooks and booklets took the bench.\n",
            "tensor([[9.9951e-01, 4.8588e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and booklets take ties.\n",
            "tensor([[9.9976e-01, 2.3714e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who looked through notebooks and booklets took knives.\n",
            "tensor([[9.9967e-01, 3.3381e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The person in the notebook and tie took a suit.\n",
            "tensor([[0.9976, 0.0024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and ties take notes.\n",
            "tensor([[9.9913e-01, 8.6985e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and ties take them into pockets.\n",
            "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and ties take a read.\n",
            "tensor([[9.9948e-01, 5.1896e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who looked at notebooks and ties took the bench.\n",
            "tensor([[9.9966e-01, 3.3552e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and ties take books.\n",
            "tensor([[9.9908e-01, 9.1745e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and ties take booklets.\n",
            "tensor([[0.9969, 0.0031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at notebooks and ties take ties.\n",
            "tensor([[9.9978e-01, 2.2152e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who looked at notebooks and ties took knives.\n",
            "tensor([[0.9563, 0.0437]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in pockets and suits take notebooks.\n",
            "tensor([[0.8589, 0.1411]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in pockets and suits take a read.\n",
            "tensor([[9.9954e-01, 4.5911e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in pockets and suits take the bench.\n",
            "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in pockets and suits take books.\n",
            "tensor([[0.9948, 0.0052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking for pockets and suits take the booklet.\n",
            "tensor([[0.5778, 0.4222]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in pockets and suits take ties.\n",
            "tensor([[0.9922, 0.0078]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking in pockets and suits take knives.\n",
            "tensor([[9.9961e-01, 3.8615e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look like pocket and notebooks take a suit.\n",
            "tensor([[0.5417, 0.4583]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and notebooks take notebooks.\n",
            "tensor([[0.9770, 0.0230]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and notebooks take their pocket.\n",
            "tensor([[0.9965, 0.0035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and notebooks take a read.\n",
            "tensor([[9.9955e-01, 4.4543e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and notebooks take to the bench.\n",
            "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and notebooks take books.\n",
            "tensor([[0.9906, 0.0094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and notebooks take booklets.\n",
            "tensor([[9.9965e-01, 3.4703e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and notebooks take ties.\n",
            "tensor([[9.9966e-01, 3.3576e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking through pockets and notebooks took a knife.\n",
            "tensor([[0.8046, 0.1954]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look through the pockets and pockets take notebooks.\n",
            "tensor([[0.9658, 0.0342]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in the pockets and pockets take a read.\n",
            "tensor([[9.9965e-01, 3.4890e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking for pockets and pockets take the bench.\n",
            "tensor([[0.9892, 0.0108]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in the pockets and pockets take books.\n",
            "tensor([[0.9956, 0.0044]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and pockets take ties.\n",
            "tensor([[0.9859, 0.0141]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking in the pockets and pockets took knives.\n",
            "tensor([[9.9944e-01, 5.6181e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in pockets and read take a suit.\n",
            "tensor([[0.8806, 0.1194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in the pocket and read take a notebook.\n",
            "tensor([[0.8757, 0.1243]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in the pockets and read take a pocket.\n",
            "tensor([[0.8482, 0.1518]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in the pocket and read take a read.\n",
            "tensor([[0.9963, 0.0037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking for pockets and reading took to the bench.\n",
            "tensor([[0.9097, 0.0903]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in the pocket and read take books.\n",
            "tensor([[0.5021, 0.4979]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in the pocket and read take the booklet.\n",
            "tensor([[9.9946e-01, 5.4328e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in pockets and read take ties.\n",
            "tensor([[9.9976e-01, 2.3648e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in pockets and read take knives.\n",
            "tensor([[9.9962e-01, 3.7876e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and benches take suits.\n",
            "tensor([[9.9980e-01, 2.0406e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at pockets and benches took notebooks.\n",
            "tensor([[9.9949e-01, 5.0607e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at pockets and benches take a pocket.\n",
            "tensor([[9.9974e-01, 2.5846e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the pockets and benches took a read.\n",
            "tensor([[9.9970e-01, 2.9644e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the pockets and benches took the bench.\n",
            "tensor([[9.9980e-01, 1.9507e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at pockets and benches take books.\n",
            "tensor([[9.9978e-01, 2.1532e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at pockets and benches took the booklet.\n",
            "tensor([[9.9973e-01, 2.6774e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the pockets and bench take ties.\n",
            "tensor([[0.9980, 0.0020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking in pockets and on benches took knives.\n",
            "tensor([[9.9912e-01, 8.8470e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and books take a suit.\n",
            "tensor([[0.9977, 0.0023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and books take notebooks.\n",
            "tensor([[0.9968, 0.0032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and books take their pocket.\n",
            "tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and books take a read.\n",
            "tensor([[9.9971e-01, 2.8755e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and books take the bench.\n",
            "tensor([[0.9981, 0.0019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and books take books.\n",
            "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and books take booklets.\n",
            "tensor([[9.9935e-01, 6.5062e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and books take ties.\n",
            "tensor([[9.9957e-01, 4.2889e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in pockets and books take knives.\n",
            "tensor([[9.9949e-01, 5.0875e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and booklets take a suit.\n",
            "tensor([[0.9969, 0.0031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and booklets take a notebook.\n",
            "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and booklets take their pocket.\n",
            "tensor([[9.9934e-01, 6.5732e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and booklets take a read.\n",
            "tensor([[9.9971e-01, 2.8711e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and booklets take the bench.\n",
            "tensor([[9.9952e-01, 4.7958e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and booklets take the book.\n",
            "tensor([[0.9964, 0.0036]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and booklets take the booklets.\n",
            "tensor([[9.9964e-01, 3.6302e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and booklets take ties.\n",
            "tensor([[9.9973e-01, 2.7259e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking through pockets and booklets take knives.\n",
            "tensor([[9.9951e-01, 4.8953e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and tie take notebooks.\n",
            "tensor([[0.7353, 0.2647]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and ties take pockets.\n",
            "tensor([[0.9978, 0.0022]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and ties take a read.\n",
            "tensor([[9.9975e-01, 2.5088e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and tie take the bench.\n",
            "tensor([[9.9975e-01, 2.5485e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and ties take the book.\n",
            "tensor([[9.9928e-01, 7.1992e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and ties take booklets.\n",
            "tensor([[9.9963e-01, 3.7473e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at pockets and ties take knives.\n",
            "tensor([[0.9813, 0.0187]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and suits take suits.\n",
            "tensor([[0.9929, 0.0071]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and suits take a notebook.\n",
            "tensor([[9.9931e-01, 6.8639e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and suits take their pockets.\n",
            "tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and suits take the read.\n",
            "tensor([[9.9976e-01, 2.4361e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and suits take to the bench.\n",
            "tensor([[9.9965e-01, 3.4661e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and suit take them.\n",
            "tensor([[0.9912, 0.0088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and suits take the booklet.\n",
            "tensor([[0.9796, 0.0204]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "\"People who look like theyre reading and in suits take ties.\"\n",
            "tensor([[9.9977e-01, 2.3098e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and suits take knives.\n",
            "tensor([[9.9951e-01, 4.8831e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and notebooks take off the suits.\n",
            "tensor([[0.9965, 0.0035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and notebooks take their pockets.\n",
            "tensor([[0.9952, 0.0048]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers take a look at the reads and notebooks.\n",
            "tensor([[0.9885, 0.0115]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and notebooks take to the bench.\n",
            "tensor([[9.9974e-01, 2.6217e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers and notebookers took ties.\n",
            "tensor([[9.9980e-01, 2.0075e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the reading and notebooks took a knife.\n",
            "tensor([[9.9981e-01, 1.9385e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and pockets take a suit.\n",
            "tensor([[0.9985, 0.0015]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look over the reads and pockets take a notebook.\n",
            "tensor([[9.9935e-01, 6.5348e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and pockets take their pockets.\n",
            "tensor([[9.9926e-01, 7.4067e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers take a read and a pocket look.\n",
            "tensor([[0.9913, 0.0087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking for reading and pockets took the bench.\n",
            "tensor([[9.9916e-01, 8.4223e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and the pockets take a book.\n",
            "tensor([[9.9962e-01, 3.8397e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers and pocketlookers take ties.\n",
            "tensor([[9.9977e-01, 2.2534e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking for a read and a pocket take a knife.\n",
            "tensor([[9.9966e-01, 3.3786e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers take a suit.\n",
            "tensor([[9.9955e-01, 4.5202e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers take their pockets.\n",
            "tensor([[9.9922e-01, 7.7742e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers take the bench.\n",
            "tensor([[9.9961e-01, 3.9484e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers take ties.\n",
            "tensor([[9.9956e-01, 4.4495e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers take knives.\n",
            "tensor([[9.9981e-01, 1.8856e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the reads and the bench take a suit.\n",
            "tensor([[0.9863, 0.0137]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the reading and the bench took a notebook.\n",
            "tensor([[9.9956e-01, 4.4246e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the reading and the bench took a pocket.\n",
            "tensor([[0.9537, 0.0463]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers take a read and bench look.\n",
            "tensor([[0.9567, 0.0433]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and the bench take a bench.\n",
            "tensor([[0.8535, 0.1465]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and the bench take books.\n",
            "tensor([[0.9862, 0.0138]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers and benchlookers take the booklet.\n",
            "tensor([[9.9966e-01, 3.4161e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the reading and the bench took ties.\n",
            "tensor([[9.9973e-01, 2.7293e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers and benchlookers took a knife.\n",
            "tensor([[9.9974e-01, 2.6078e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and read take a suit.\n",
            "tensor([[9.9911e-01, 8.8880e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and books take their pocket.\n",
            "tensor([[0.9947, 0.0053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and books take the bench.\n",
            "tensor([[9.9969e-01, 3.0754e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and read take ties.\n",
            "tensor([[9.9976e-01, 2.3972e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and the books take knives.\n",
            "tensor([[9.9957e-01, 4.3077e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and booklets take their suits.\n",
            "tensor([[9.9920e-01, 8.0332e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and booklets take their pockets.\n",
            "tensor([[0.9801, 0.0199]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and booklets take the bench.\n",
            "tensor([[9.9937e-01, 6.2704e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and booklets take ties.\n",
            "tensor([[9.9977e-01, 2.2900e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and booklets take a knife.\n",
            "tensor([[9.9911e-01, 8.8637e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reading and tie take a notebook.\n",
            "tensor([[9.9951e-01, 4.9157e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and tie take their pockets.\n",
            "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "Readers who look at the reads and theties take the read.\n",
            "tensor([[9.9971e-01, 2.9291e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and tie take the bench.\n",
            "tensor([[9.9922e-01, 7.8187e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and theties take the book.\n",
            "tensor([[9.9948e-01, 5.2012e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the reads and the ties take ties.\n",
            "tensor([[9.9981e-01, 1.9077e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the reads and theties took knives.\n",
            "tensor([[0.9056, 0.0944]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look on the bench and in suits take suits.\n",
            "tensor([[9.9974e-01, 2.5644e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and suits took a notebook.\n",
            "tensor([[0.9669, 0.0331]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "\"People who look like theyre on the bench and in suits take their pockets.\"\n",
            "tensor([[9.9978e-01, 2.1988e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the bench and suit take a read.\n",
            "tensor([[9.9977e-01, 2.3029e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and suits take the bench.\n",
            "tensor([[9.9982e-01, 1.7996e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the bench and suits take the book.\n",
            "tensor([[9.9983e-01, 1.7242e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking for a bench and suit take the booklet.\n",
            "tensor([[0.9982, 0.0018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "\"People who look like theyre on the bench and in suits take ties.\"\n",
            "tensor([[9.9980e-01, 1.9908e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the bench and suit take knives.\n",
            "tensor([[9.9984e-01, 1.6418e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and notebooks took a suit.\n",
            "tensor([[0.9713, 0.0287]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and notebooks took a notebook.\n",
            "tensor([[9.9974e-01, 2.5887e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and notebooks took a pocket.\n",
            "tensor([[0.9945, 0.0055]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look over the bench and notebooks take a read.\n",
            "tensor([[9.9926e-01, 7.3679e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and notebooks take a bench.\n",
            "tensor([[9.9973e-01, 2.6609e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and notebooks take books.\n",
            "tensor([[9.9974e-01, 2.5910e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and notebooks take the booklet.\n",
            "tensor([[9.9978e-01, 2.1983e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and notebooks took ties.\n",
            "tensor([[9.9981e-01, 1.9458e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and notebooks took knives.\n",
            "tensor([[9.9981e-01, 1.9369e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and pocket take a suit.\n",
            "tensor([[9.9979e-01, 2.1209e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and pocket took a notebook.\n",
            "tensor([[9.9942e-01, 5.7967e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and pockets take a pocket.\n",
            "tensor([[9.9966e-01, 3.4458e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and pocket took a read.\n",
            "tensor([[9.9962e-01, 3.7635e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and pocket take a bench.\n",
            "tensor([[9.9972e-01, 2.8300e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and pocket take a book.\n",
            "tensor([[9.9971e-01, 2.8522e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and pocket took the booklet.\n",
            "tensor([[9.9978e-01, 2.1855e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and pocket take ties.\n",
            "tensor([[9.9981e-01, 1.9308e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and pocket took a knife.\n",
            "tensor([[9.9963e-01, 3.6610e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and reading take a suit.\n",
            "tensor([[0.8575, 0.1425]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and reading took a notebook.\n",
            "tensor([[0.9979, 0.0021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and reading took their pockets.\n",
            "tensor([[0.6098, 0.3902]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look over the bench and read take the booklet.\n",
            "tensor([[9.9925e-01, 7.5463e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and reading took ties.\n",
            "tensor([[9.9979e-01, 2.1368e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and reading took a knife.\n",
            "tensor([[9.9981e-01, 1.9071e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and the benches take a suit.\n",
            "tensor([[9.9940e-01, 5.9514e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and the benches take a notebook.\n",
            "tensor([[9.9976e-01, 2.3718e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and the bench took a pocket.\n",
            "tensor([[0.9989, 0.0011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and the benches take a read.\n",
            "tensor([[9.9971e-01, 2.8576e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and the benches take the book.\n",
            "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and benches take the booklet.\n",
            "tensor([[9.9971e-01, 2.8926e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the benches and benches take ties.\n",
            "tensor([[9.9979e-01, 2.1357e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and the bench took a knife.\n",
            "tensor([[9.9979e-01, 2.1041e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and books take a suit.\n",
            "tensor([[9.9921e-01, 7.9235e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and books took a notebook.\n",
            "tensor([[9.9961e-01, 3.9141e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and books take their pockets.\n",
            "tensor([[0.9954, 0.0046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and books take a bench.\n",
            "tensor([[9.9902e-01, 9.8331e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the bench and books take books.\n",
            "tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and books take booklets.\n",
            "tensor([[9.9973e-01, 2.6957e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and books take ties.\n",
            "tensor([[9.9976e-01, 2.3735e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and the books took knives.\n",
            "tensor([[9.9981e-01, 1.9415e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and booklets take a suit.\n",
            "tensor([[9.9933e-01, 6.6784e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the benches and booklets took a notebook.\n",
            "tensor([[9.9932e-01, 6.7980e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and booklets took their pockets.\n",
            "tensor([[0.9987, 0.0013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and booklets take a read.\n",
            "tensor([[9.9976e-01, 2.3544e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and booklets take a look at the bench.\n",
            "tensor([[9.9939e-01, 6.0510e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and booklets take the book.\n",
            "tensor([[0.9976, 0.0024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the benches and booklets take the booklets.\n",
            "tensor([[9.9977e-01, 2.2607e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the benches and booklets took ties.\n",
            "tensor([[9.9981e-01, 1.9221e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and booklets took knives.\n",
            "tensor([[0.9659, 0.0341]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in bench and tie take suits.\n",
            "tensor([[9.9984e-01, 1.6439e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the benches and tie took a notebook.\n",
            "tensor([[9.9978e-01, 2.1970e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and tie took a pocket.\n",
            "tensor([[9.9979e-01, 2.1432e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and tie took a read.\n",
            "tensor([[9.9960e-01, 3.9971e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the benches and ties take a bench.\n",
            "tensor([[9.9982e-01, 1.8233e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the bench and tie take the book.\n",
            "tensor([[9.9984e-01, 1.5737e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the benches and ties take the booklet.\n",
            "tensor([[9.9961e-01, 3.8673e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the bench and tie take ties.\n",
            "tensor([[9.9981e-01, 1.9270e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the benches and ties took knives.\n",
            "tensor([[0.6904, 0.3096]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and suits take suits.\n",
            "tensor([[0.9900, 0.0100]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and suits take notebooks.\n",
            "tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and suits take their pockets.\n",
            "tensor([[9.9967e-01, 3.3471e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and suits take a read.\n",
            "tensor([[9.9961e-01, 3.9023e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in the books and suits take the bench.\n",
            "tensor([[0.9946, 0.0054]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and suits take books.\n",
            "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and suits take the booklet.\n",
            "tensor([[9.9968e-01, 3.1820e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in a book and suit take ties.\n",
            "tensor([[9.9978e-01, 2.2285e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and suits take knives.\n",
            "tensor([[9.9974e-01, 2.5582e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and notebooks take a suit.\n",
            "tensor([[0.9965, 0.0035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and notebooks take them into pockets.\n",
            "tensor([[0.9932, 0.0068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and notebooks take the bench.\n",
            "tensor([[9.9967e-01, 3.3381e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and notebooks take ties.\n",
            "tensor([[9.9977e-01, 2.3223e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and notebooks take knives.\n",
            "tensor([[9.9957e-01, 4.2953e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and pockets take a suit.\n",
            "tensor([[0.9972, 0.0028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and pockets take notebooks.\n",
            "tensor([[9.9931e-01, 6.8619e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and pockets take a pocket.\n",
            "tensor([[9.9963e-01, 3.6891e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and pockets take a read.\n",
            "tensor([[9.9942e-01, 5.7698e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and pockets take a bench.\n",
            "tensor([[0.9971, 0.0029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and pockets take books.\n",
            "tensor([[0.9961, 0.0039]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and pockets take the booklet.\n",
            "tensor([[9.9967e-01, 3.3138e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and pockets take ties.\n",
            "tensor([[9.9961e-01, 3.8529e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking through the books and pockets took a knife.\n",
            "tensor([[9.9976e-01, 2.3867e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and read take a suit.\n",
            "tensor([[9.9934e-01, 6.5643e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and read take their pockets.\n",
            "tensor([[0.9730, 0.0270]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and read take the bench.\n",
            "tensor([[9.9972e-01, 2.8265e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and read take ties.\n",
            "tensor([[9.9977e-01, 2.3136e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and read take a knife.\n",
            "tensor([[9.9973e-01, 2.6888e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and the benches take suits.\n",
            "tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and the benches take notebooks.\n",
            "tensor([[9.9970e-01, 3.0165e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and the benches take their pockets.\n",
            "tensor([[0.9984, 0.0016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and the benches take a read.\n",
            "tensor([[0.9303, 0.0697]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and the benches take the bench.\n",
            "tensor([[9.9956e-01, 4.3536e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and the benches take them.\n",
            "tensor([[9.9980e-01, 2.0309e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and the benches take the booklet.\n",
            "tensor([[9.9972e-01, 2.8232e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the books and the benches took ties.\n",
            "tensor([[9.9977e-01, 2.3316e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the books and the benches took knives.\n",
            "tensor([[9.9976e-01, 2.3584e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and books take suits.\n",
            "tensor([[9.9951e-01, 4.8503e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and books take their pockets.\n",
            "tensor([[0.9919, 0.0081]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and books take the bench.\n",
            "tensor([[9.9974e-01, 2.5690e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and books take ties.\n",
            "tensor([[9.9978e-01, 2.2401e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and books take knives.\n",
            "tensor([[9.9961e-01, 3.9474e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and booklets take a suit.\n",
            "tensor([[0.7900, 0.2100]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and booklets take them into pockets.\n",
            "tensor([[0.9926, 0.0074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and booklets take the bench.\n",
            "tensor([[9.9959e-01, 4.0771e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and booklets take ties.\n",
            "tensor([[9.9976e-01, 2.3763e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and booklets take knives.\n",
            "tensor([[0.9939, 0.0061]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in books and ties take suits.\n",
            "tensor([[9.9955e-01, 4.4747e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and ties take a notebook.\n",
            "tensor([[9.9954e-01, 4.5968e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and ties take their pockets.\n",
            "tensor([[0.9874, 0.0126]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and ties take a read.\n",
            "tensor([[0.9931, 0.0069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "The book and tie lookers took the bench.\n",
            "tensor([[0.9818, 0.0182]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and ties take books.\n",
            "tensor([[0.9985, 0.0015]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and ties take the booklet.\n",
            "tensor([[0.9982, 0.0018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at books and ties take ties.\n",
            "tensor([[9.9976e-01, 2.3527e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the books and ties take knives.\n",
            "tensor([[0.9493, 0.0507]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and suits take suits.\n",
            "tensor([[0.9882, 0.0118]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the booklets and suits take a notebook.\n",
            "tensor([[0.9965, 0.0035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and suits take their pockets.\n",
            "tensor([[9.9940e-01, 5.9874e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the booklets and suits take a read.\n",
            "tensor([[9.9968e-01, 3.1864e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the booklets and suits take the bench.\n",
            "tensor([[0.9952, 0.0048]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the booklets and suits take the book.\n",
            "tensor([[0.9962, 0.0038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the booklet and suit take the booklet.\n",
            "tensor([[0.9981, 0.0019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look in booklets and suits take ties.\n",
            "tensor([[9.9983e-01, 1.7185e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at booklets and suits took knives.\n",
            "tensor([[9.9904e-01, 9.6025e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and notebooks take suits.\n",
            "tensor([[0.9104, 0.0896]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and notebooks take them into pockets.\n",
            "tensor([[9.9918e-01, 8.2329e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who looked through the booklets and notebooks took the bench.\n",
            "tensor([[9.9963e-01, 3.6876e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at booklets and notebooks took ties.\n",
            "tensor([[9.9978e-01, 2.2392e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who looked through the booklets and notebooks took a knife.\n",
            "tensor([[9.9978e-01, 2.2081e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at booklets and pockets took a suit.\n",
            "tensor([[0.9835, 0.0165]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and pockets take a notebook.\n",
            "tensor([[0.9245, 0.0755]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and pockets take them out of the pocket.\n",
            "tensor([[0.9161, 0.0839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the booklets and pockets take a read.\n",
            "tensor([[9.9933e-01, 6.7156e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and pockets take to the bench.\n",
            "tensor([[0.9934, 0.0066]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and pockets take the book.\n",
            "tensor([[0.9980, 0.0020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and pockets take them.\n",
            "tensor([[9.9971e-01, 2.9334e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at booklets and pockets took ties.\n",
            "tensor([[9.9972e-01, 2.7941e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking through the booklets and pockets took a knife.\n",
            "tensor([[9.9954e-01, 4.6391e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the booklets and read take a suit.\n",
            "tensor([[0.9886, 0.0114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and read take the bench.\n",
            "tensor([[9.9972e-01, 2.8491e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the booklets and read take ties.\n",
            "tensor([[9.9976e-01, 2.3639e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the booklets and read take a knife.\n",
            "tensor([[9.9982e-01, 1.8263e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the booklets and the benches took a suit.\n",
            "tensor([[0.9985, 0.0015]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and benches take notes.\n",
            "tensor([[9.9949e-01, 5.0915e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at booklets and benches took their pockets.\n",
            "tensor([[0.9973, 0.0027]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and benches take a read.\n",
            "tensor([[0.9990, 0.0010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the booklet and the benches take a bench.\n",
            "tensor([[0.9961, 0.0039]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and benches take books.\n",
            "tensor([[9.9980e-01, 1.9804e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the booklets and the benches take them.\n",
            "tensor([[9.9972e-01, 2.7668e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the booklets and the benches took ties.\n",
            "tensor([[9.9983e-01, 1.6669e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People looking at the booklet and the bench took a knife.\n",
            "tensor([[9.9955e-01, 4.4745e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and books take suits.\n",
            "tensor([[0.5166, 0.4834]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and books take them into pockets.\n",
            "tensor([[0.9947, 0.0053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and books take the bench.\n",
            "tensor([[9.9965e-01, 3.5067e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and books take ties.\n",
            "tensor([[9.9978e-01, 2.2304e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and books take knives.\n",
            "tensor([[9.9971e-01, 2.9254e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and booklets take a suit.\n",
            "tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and booklets take the bench.\n",
            "tensor([[9.9945e-01, 5.5191e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and booklets take ties.\n",
            "tensor([[9.9977e-01, 2.3041e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at the booklets and the booklets take knives.\n",
            "tensor([[0.9964, 0.0036]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
            "People who look at booklets and ties take suits.\n",
            "Generated annotations:\n",
            "Model predicted that 180/1000 sentences are common sense.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load the best-trained model\n",
        "model.load_state_dict(torch.load(model_params_path))\n",
        "\n",
        "# Get test data by DataLoader\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Start testing\n",
        "model.eval()\n",
        "\n",
        "counter = 0\n",
        "correct = 0\n",
        "count = 0\n",
        "accuracy = 0\n",
        "\n",
        "\n",
        "for idx in range(len(test_texts)):\n",
        "  statement = test_texts.iloc[idx]\n",
        "  # Tokenization for two statements\n",
        "  # inputs = tokenizer(statement_1, statement_2, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
        "  inputs = tokenizer(statement, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "  # Model makes its prediction\n",
        "  outputs = model(**inputs)\n",
        "  probabilities = torch.softmax(outputs[\"logits\"], dim=1)\n",
        "  predictions = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "  # count accuracy\n",
        "  if int(predictions) == 0 and test_labels.iloc[idx] == 0:\n",
        "    correct += 1\n",
        "  elif int(predictions) == 1 and test_labels.iloc[idx] == 1:\n",
        "    correct += 1\n",
        "\n",
        "count = len(test_texts)\n",
        "accuracy = correct * 1.0 / count\n",
        "\n",
        "print(\"Results on test set of ComVE\")\n",
        "print(\"Number of total examples: \")\n",
        "print(count)\n",
        "print('Accuracy {:.3f}'.format(accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aFXkTsA-Xqp",
        "outputId": "ec49ece5-15f2-45b5-ff74-cc4d78602db0"
      },
      "id": "2aFXkTsA-Xqp",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1778\n",
            "2000\n",
            "Accuracy 0.889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o0WRbr37bQmW"
      },
      "id": "o0WRbr37bQmW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "name": "Subtask_A.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}